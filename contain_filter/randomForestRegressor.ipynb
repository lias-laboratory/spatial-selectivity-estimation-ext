{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c11912e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T22:51:02.159189Z",
     "iopub.status.busy": "2025-03-24T22:51:02.158525Z",
     "iopub.status.idle": "2025-03-24T23:38:23.733041Z",
     "shell.execute_reply": "2025-03-24T23:38:23.732058Z"
    },
    "papermill": {
     "duration": 2841.585166,
     "end_time": "2025-03-24T23:38:23.735352",
     "exception": false,
     "start_time": "2025-03-24T22:51:02.150186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 29 of 30 available CPU cores\n",
      "Loading spatial statistics...\n",
      "Finding dataset files...\n",
      "Found 14 datasets to process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d9931cb7f14b94990452967d5e73b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing datasets:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 248.05 MB\n",
      "\n",
      "Processing dataset: craftwaysorted\n",
      "Universe boundaries for craftwaysorted: (-175.2000514, -65.2458821, 175.3397782, 69.6673353)\n",
      "Loading data from ../large_files/resultsContains/craftwaysorted_results.csv\n",
      "Parsing MBR coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for craftwaysorted dataset:\n",
      "Max count: 108929.0\n",
      "Min count: 0.0\n",
      "Mean count: 1705.23\n",
      "Median count: 0.00\n",
      "Total samples: 21822\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 17457\n",
      "\n",
      "Training with sample size: 17457\n",
      "Memory usage: 253.88 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 516.26s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 26118.71 KB\n",
      "\n",
      "Results for craftwaysorted, Sample Size: 17457\n",
      "Grid Search Time: 516.26s, Training Time: 21.33s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9930, MAE = 177.36, MAPE = 76.38%\n",
      "q-score: 2.63\n",
      "Prediction time: 132.6213 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 592.42 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 16075.59 KB\n",
      "\n",
      "Results for craftwaysorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 12.23s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9885, MAE = 246.89, MAPE = 142.28%\n",
      "q-score: 3.89\n",
      "Prediction time: 119.1111 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 594.73 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 8795.09 KB\n",
      "\n",
      "Results for craftwaysorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 6.38s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9710, MAE = 406.07, MAPE = 241.09%\n",
      "q-score: 5.68\n",
      "Prediction time: 105.4785 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000046\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 595.99 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 2042.30 KB\n",
      "\n",
      "Results for craftwaysorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 2.00s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.7581, MAE = 1211.04, MAPE = 724.83%\n",
      "q-score: 14.54\n",
      "Prediction time: 83.7709 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results for craftwaysorted...\n",
      "Memory usage: 595.99 MB\n",
      "\n",
      "Processing dataset: powerthingwaysorted\n",
      "Universe boundaries for powerthingwaysorted: (-179.5002188, -75.1012051, 178.4574038, 82.5247908)\n",
      "Loading data from ../large_files/resultsContains/powerthingwaysorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing MBR coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for powerthingwaysorted dataset:\n",
      "Max count: 13586342.0\n",
      "Min count: 0.0\n",
      "Mean count: 236375.56\n",
      "Median count: 147.00\n",
      "Total samples: 2717289\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 2173831\n",
      "\n",
      "Training with sample size: 2173831\n",
      "Memory usage: 890.32 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 2401.23s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 538753.97 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 2173831\n",
      "Grid Search Time: 2401.23s, Training Time: 1570.54s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9997, MAE = 4033.80, MAPE = 34.03%\n",
      "q-score: 1.57\n",
      "Prediction time: 32.3984 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 2000000\n",
      "Memory usage: 7397.52 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 497036.57 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 2000000\n",
      "Grid Search Time: 0.00s, Training Time: 1331.68s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9997, MAE = 4176.99, MAPE = 36.66%\n",
      "q-score: 1.61\n",
      "Prediction time: 31.6109 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000003\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000000\n",
      "Memory usage: 1729.38 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 255111.17 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 1000000\n",
      "Grid Search Time: 0.00s, Training Time: 584.27s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9995, MAE = 5585.67, MAPE = 56.41%\n",
      "q-score: 1.93\n",
      "Prediction time: 26.5854 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 500000\n",
      "Memory usage: 2361.52 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 131302.85 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 500000\n",
      "Grid Search Time: 0.00s, Training Time: 284.04s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9991, MAE = 7209.09, MAPE = 96.84%\n",
      "q-score: 2.54\n",
      "Prediction time: 20.8820 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.001071\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 2452.70 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 28621.34 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 37.91s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9975, MAE = 13569.43, MAPE = 427.99%\n",
      "q-score: 7.25\n",
      "Prediction time: 10.6838 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 2452.70 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 15005.78 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 18.40s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9955, MAE = 18901.23, MAPE = 977.18%\n",
      "q-score: 14.47\n",
      "Prediction time: 9.0168 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 2452.72 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 3373.01 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 3.17s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9734, MAE = 46658.35, MAPE = 4708.46%\n",
      "q-score: 62.78\n",
      "Prediction time: 6.7792 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 2452.72 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 1816.80 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 1.81s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9505, MAE = 68256.15, MAPE = 12194.53%\n",
      "q-score: 155.49\n",
      "Prediction time: 6.1424 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 2452.72 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 423.21 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.44s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.6973, MAE = 159340.59, MAPE = 44630.58%\n",
      "q-score: 525.90\n",
      "Prediction time: 4.4173 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for powerthingwaysorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 2386.38 MB\n",
      "\n",
      "Processing dataset: barrierthingwaysorted\n",
      "Universe boundaries for barrierthingwaysorted: (-179.7595238, -70.776382, 179.19591350000002, 78.2501675)\n",
      "Loading data from ../large_files/resultsContains/barrierthingwaysorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing MBR coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for barrierthingwaysorted dataset:\n",
      "Max count: 22908267.0\n",
      "Min count: 0.0\n",
      "Mean count: 399928.77\n",
      "Median count: 329.00\n",
      "Total samples: 4581670\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 3665336\n",
      "\n",
      "Training with sample size: 3665336\n",
      "Memory usage: 2603.68 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 4470.64s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 932288.69 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 3665336\n",
      "Grid Search Time: 4470.64s, Training Time: 2584.46s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9999, MAE = 4565.82, MAPE = 36.65%\n",
      "q-score: 1.58\n",
      "Prediction time: 39.7301 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000002\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 3000000\n",
      "Memory usage: 11521.09 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 770869.02 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 3000000\n",
      "Grid Search Time: 0.00s, Training Time: 2197.97s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9998, MAE = 4919.48, MAPE = 41.33%\n",
      "q-score: 1.65\n",
      "Prediction time: 37.3730 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000002\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 2000000\n",
      "Memory usage: 5249.31 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 524566.79 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 2000000\n",
      "Grid Search Time: 0.00s, Training Time: 1270.78s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9998, MAE = 5720.03, MAPE = 51.96%\n",
      "q-score: 1.81\n",
      "Prediction time: 33.7494 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000000\n",
      "Memory usage: 5263.32 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 271711.24 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 1000000\n",
      "Grid Search Time: 0.00s, Training Time: 606.89s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9996, MAE = 7535.56, MAPE = 84.99%\n",
      "q-score: 2.30\n",
      "Prediction time: 28.4888 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000002\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 500000\n",
      "Memory usage: 5263.32 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 140770.50 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 500000\n",
      "Grid Search Time: 0.00s, Training Time: 267.08s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9994, MAE = 9718.14, MAPE = 124.14%\n",
      "q-score: 2.87\n",
      "Prediction time: 22.2827 μs/sample\n",
      "I/O: Reads=0.000006, Writes=0.000680\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 5263.32 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 30704.15 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 39.84s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9980, MAE = 18860.94, MAPE = 413.87%\n",
      "q-score: 6.76\n",
      "Prediction time: 10.8221 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 5263.32 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 16012.79 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 16.37s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9964, MAE = 26031.70, MAPE = 778.11%\n",
      "q-score: 11.51\n",
      "Prediction time: 8.8754 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 5263.32 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 3588.49 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 3.13s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9840, MAE = 62728.01, MAPE = 4288.20%\n",
      "q-score: 51.76\n",
      "Prediction time: 6.6766 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 5263.32 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 1915.50 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 1.68s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9687, MAE = 87991.35, MAPE = 9436.73%\n",
      "q-score: 113.15\n",
      "Prediction time: 5.9193 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 5263.32 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 436.70 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.49s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.6708, MAE = 316902.07, MAPE = 84250.18%\n",
      "q-score: 965.55\n",
      "Prediction time: 4.3613 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000349\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for barrierthingwaysorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 5116.51 MB\n",
      "\n",
      "Processing dataset: cyclewaythingwaysorted\n",
      "Universe boundaries for cyclewaythingwaysorted: (-175.2093065, -75.1027861, 176.92582230000002, 71.0488105)\n",
      "Loading data from ../large_files/resultsContains/cyclewaythingwaysorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing MBR coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for cyclewaythingwaysorted dataset:\n",
      "Max count: 5334899.0\n",
      "Min count: 0.0\n",
      "Mean count: 76781.20\n",
      "Median count: 0.00\n",
      "Total samples: 1067063\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 853650\n",
      "\n",
      "Training with sample size: 853650\n",
      "Memory usage: 4977.68 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 741.48s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 157646.25 KB\n",
      "\n",
      "Results for cyclewaythingwaysorted, Sample Size: 853650\n",
      "Grid Search Time: 741.48s, Training Time: 478.04s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9995, MAE = 1628.53, MAPE = 36.07%\n",
      "q-score: 1.69\n",
      "Prediction time: 20.8158 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 500000\n",
      "Memory usage: 5041.36 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 97260.32 KB\n",
      "\n",
      "Results for cyclewaythingwaysorted, Sample Size: 500000\n",
      "Grid Search Time: 0.00s, Training Time: 263.30s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9992, MAE = 2050.00, MAPE = 51.90%\n",
      "q-score: 1.97\n",
      "Prediction time: 17.2618 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 4977.20 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 22703.34 KB\n",
      "\n",
      "Results for cyclewaythingwaysorted, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 37.42s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9971, MAE = 4216.72, MAPE = 179.87%\n",
      "q-score: 4.13\n",
      "Prediction time: 10.1139 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 4977.20 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 12154.59 KB\n",
      "\n",
      "Results for cyclewaythingwaysorted, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 17.92s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9947, MAE = 5945.07, MAPE = 321.14%\n",
      "q-score: 6.15\n",
      "Prediction time: 8.8802 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 4977.20 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 2898.88 KB\n",
      "\n",
      "Results for cyclewaythingwaysorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 3.27s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9790, MAE = 14001.04, MAPE = 1967.16%\n",
      "q-score: 28.86\n",
      "Prediction time: 7.1053 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000002\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 4977.20 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 1572.15 KB\n",
      "\n",
      "Results for cyclewaythingwaysorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 1.69s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9449, MAE = 22988.67, MAPE = 5129.48%\n",
      "q-score: 75.07\n",
      "Prediction time: 6.3134 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 4977.20 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 361.25 KB\n",
      "\n",
      "Results for cyclewaythingwaysorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.48s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.7425, MAE = 54258.18, MAPE = 14276.35%\n",
      "q-score: 180.98\n",
      "Prediction time: 4.8667 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for cyclewaythingwaysorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 4977.20 MB\n",
      "\n",
      "Processing dataset: zcta5\n",
      "Universe boundaries for zcta5: (-176.684744, -14.373776, 145.830505, 71.341324)\n",
      "Loading data from ../large_files/resultsContains/zcta5_results.csv\n",
      "Parsing MBR coordinates...\n",
      "\n",
      "Basic statistics for zcta5 dataset:\n",
      "Max count: 33131.0\n",
      "Min count: 0.0\n",
      "Mean count: 662.21\n",
      "Median count: 0.00\n",
      "Total samples: 6626\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 5300\n",
      "\n",
      "Training with sample size: 5300\n",
      "Memory usage: 4977.20 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 165.35s\n",
      "Best parameters: {'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 929.95 KB\n",
      "\n",
      "Results for zcta5, Sample Size: 5300\n",
      "Grid Search Time: 165.35s, Training Time: 2.40s\n",
      "Random Forest Parameters: {'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Performance: R² = 0.9841, MAE = 104.65, MAPE = 57.99%\n",
      "q-score: 5.39\n",
      "Prediction time: 78.5020 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000151\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 4977.19 MB\n",
      "Using best parameters from max scale: {'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 855.97 KB\n",
      "\n",
      "Results for zcta5, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 2.18s\n",
      "Random Forest Parameters: {'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Performance: R² = 0.9803, MAE = 114.33, MAPE = 63.35%\n",
      "q-score: 5.16\n",
      "Prediction time: 76.6533 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 4977.20 MB\n",
      "Using best parameters from max scale: {'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 230.63 KB\n",
      "\n",
      "Results for zcta5, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.77s\n",
      "Random Forest Parameters: {'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Performance: R² = 0.8614, MAE = 311.82, MAPE = 297.22%\n",
      "q-score: 21.52\n",
      "Prediction time: 75.9914 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for zcta5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 4977.20 MB\n",
      "\n",
      "Processing dataset: aerowaythingnodesorted\n",
      "Universe boundaries for aerowaythingnodesorted: (-179.88088960000002, -90.0, 179.951004, 83.08333590000001)\n",
      "Loading data from ../large_files/resultsContains/aerowaythingnodesorted_results.csv\n",
      "Parsing MBR coordinates...\n",
      "\n",
      "Basic statistics for aerowaythingnodesorted dataset:\n",
      "Max count: 79139.0\n",
      "Min count: 0.0\n",
      "Mean count: 1260.61\n",
      "Median count: 7.00\n",
      "Total samples: 15843\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 12674\n",
      "\n",
      "Training with sample size: 12674\n",
      "Memory usage: 4977.20 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 406.55s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 28501.57 KB\n",
      "\n",
      "Results for aerowaythingnodesorted, Sample Size: 12674\n",
      "Grid Search Time: 406.55s, Training Time: 16.67s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9781, MAE = 252.63, MAPE = 462.65%\n",
      "q-score: 8.32\n",
      "Prediction time: 163.8801 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000347\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n",
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 5002.12 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 22810.09 KB\n",
      "\n",
      "Results for aerowaythingnodesorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 13.54s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9784, MAE = 271.26, MAPE = 493.46%\n",
      "q-score: 8.79\n",
      "Prediction time: 159.6236 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000126\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 5002.12 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 12036.63 KB\n",
      "\n",
      "Results for aerowaythingnodesorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 6.58s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9613, MAE = 372.63, MAPE = 730.61%\n",
      "q-score: 12.55\n",
      "Prediction time: 136.5113 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 5002.12 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 2764.45 KB\n",
      "\n",
      "Results for aerowaythingnodesorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 2.08s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.8061, MAE = 860.53, MAPE = 3130.52%\n",
      "q-score: 49.29\n",
      "Prediction time: 108.3495 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for aerowaythingnodesorted...\n",
      "Memory usage: 5002.12 MB\n",
      "\n",
      "Processing dataset: leisurewaysorted\n",
      "Universe boundaries for leisurewaysorted: (-179.8728244, -89.6957847, 179.8091866, 81.0280175)\n",
      "Loading data from ../large_files/resultsContains/leisurewaysorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing MBR coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for leisurewaysorted dataset:\n",
      "Max count: 29382686.0\n",
      "Min count: 0.0\n",
      "Mean count: 489264.44\n",
      "Median count: 253.00\n",
      "Total samples: 5000000\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 4000000\n",
      "\n",
      "Training with sample size: 4000000\n",
      "Memory usage: 5004.13 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 4961.25s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 981594.79 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 4000000\n",
      "Grid Search Time: 4961.25s, Training Time: 3054.71s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9998, MAE = 5872.38, MAPE = 35.93%\n",
      "q-score: 1.59\n",
      "Prediction time: 37.3048 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000002\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 3000000\n",
      "Memory usage: 12502.58 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 745237.68 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 3000000\n",
      "Grid Search Time: 0.00s, Training Time: 2219.63s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9998, MAE = 6546.37, MAPE = 44.31%\n",
      "q-score: 1.71\n",
      "Prediction time: 34.7906 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000002\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 2000000\n",
      "Memory usage: 5181.01 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 505632.54 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 2000000\n",
      "Grid Search Time: 0.00s, Training Time: 1271.99s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9998, MAE = 7430.45, MAPE = 55.71%\n",
      "q-score: 1.89\n",
      "Prediction time: 31.4011 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000003\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000000\n",
      "Memory usage: 5058.84 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 260816.08 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 1000000\n",
      "Grid Search Time: 0.00s, Training Time: 609.80s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9996, MAE = 9651.29, MAPE = 86.80%\n",
      "q-score: 2.34\n",
      "Prediction time: 26.7701 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 500000\n",
      "Memory usage: 5109.34 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 134834.45 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 500000\n",
      "Grid Search Time: 0.00s, Training Time: 268.92s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9993, MAE = 12754.99, MAPE = 148.19%\n",
      "q-score: 5.11\n",
      "Prediction time: 20.7714 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 5111.14 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 29432.23 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 37.92s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9979, MAE = 24702.93, MAPE = 562.14%\n",
      "q-score: 9.16\n",
      "Prediction time: 10.3765 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 5111.14 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 15398.64 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 19.13s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9965, MAE = 33924.79, MAPE = 1195.19%\n",
      "q-score: 17.47\n",
      "Prediction time: 8.6570 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 5066.61 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 3477.00 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 3.44s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9847, MAE = 77848.14, MAPE = 7937.88%\n",
      "q-score: 95.99\n",
      "Prediction time: 6.5057 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 5067.44 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 1864.13 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 1.65s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9671, MAE = 115862.01, MAPE = 17399.34%\n",
      "q-score: 198.81\n",
      "Prediction time: 5.7300 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 5067.44 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 429.43 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.41s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.7109, MAE = 373397.40, MAPE = 123149.57%\n",
      "q-score: 1427.17\n",
      "Prediction time: 4.2613 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000204\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for leisurewaysorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 5067.44 MB\n",
      "\n",
      "Processing dataset: areawater\n",
      "Universe boundaries for areawater: (-179.231086, -14.601813, 179.859681, 71.441059)\n",
      "Loading data from ../large_files/resultsContains/areawater_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing MBR coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for areawater dataset:\n",
      "Max count: 2292728.0\n",
      "Min count: 0.0\n",
      "Mean count: 43929.12\n",
      "Median count: 0.00\n",
      "Total samples: 458552\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 366841\n",
      "\n",
      "Training with sample size: 366841\n",
      "Memory usage: 5069.45 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 234.86s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 24039.10 KB\n",
      "\n",
      "Results for areawater, Sample Size: 366841\n",
      "Grid Search Time: 234.86s, Training Time: 159.40s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9995, MAE = 838.24, MAPE = 13.31%\n",
      "q-score: 1.91\n",
      "Prediction time: 7.9652 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000005\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n",
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 5072.37 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 7281.53 KB\n",
      "\n",
      "Results for areawater, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 30.03s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9984, MAE = 1584.76, MAPE = 34.75%\n",
      "q-score: 3.21\n",
      "Prediction time: 6.5442 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000653\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 5072.37 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 3880.56 KB\n",
      "\n",
      "Results for areawater, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 14.15s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9972, MAE = 2204.74, MAPE = 66.67%\n",
      "q-score: 4.47\n",
      "Prediction time: 5.9234 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 5072.37 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 957.56 KB\n",
      "\n",
      "Results for areawater, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 2.71s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9881, MAE = 4897.53, MAPE = 355.94%\n",
      "q-score: 16.72\n",
      "Prediction time: 5.3527 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 5072.37 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 545.17 KB\n",
      "\n",
      "Results for areawater, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 1.24s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9766, MAE = 7203.62, MAPE = 1080.28%\n",
      "q-score: 43.52\n",
      "Prediction time: 5.1295 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 5072.37 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 124.17 KB\n",
      "\n",
      "Results for areawater, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.40s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9212, MAE = 16857.60, MAPE = 6133.97%\n",
      "q-score: 231.51\n",
      "Prediction time: 4.1341 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for areawater...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 5072.37 MB\n",
      "\n",
      "Processing dataset: yago2\n",
      "Universe boundaries for yago2: (-179.98473, -90.0, 180.0, 90.0)\n",
      "Loading data from ../large_files/resultsContains/yago2_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing MBR coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for yago2 dataset:\n",
      "Max count: 4494666.0\n",
      "Min count: 0.0\n",
      "Mean count: 79087.58\n",
      "Median count: 678.00\n",
      "Total samples: 898942\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 719153\n",
      "\n",
      "Training with sample size: 719153\n",
      "Memory usage: 5076.36 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 668.51s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 290539.21 KB\n",
      "\n",
      "Results for yago2, Sample Size: 719153\n",
      "Grid Search Time: 668.51s, Training Time: 426.09s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9993, MAE = 2305.45, MAPE = 88.10%\n",
      "q-score: 1.98\n",
      "Prediction time: 39.5674 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000006\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 500000\n",
      "Memory usage: 6071.79 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 205209.46 KB\n",
      "\n",
      "Results for yago2, Sample Size: 500000\n",
      "Grid Search Time: 0.00s, Training Time: 272.49s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9990, MAE = 2631.08, MAPE = 121.24%\n",
      "q-score: 2.35\n",
      "Prediction time: 35.2524 μs/sample\n",
      "I/O: Reads=0.000032, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 5117.80 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 43807.03 KB\n",
      "\n",
      "Results for yago2, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 38.76s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9966, MAE = 5226.34, MAPE = 491.38%\n",
      "q-score: 6.43\n",
      "Prediction time: 16.9028 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000002\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 5117.80 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 22403.95 KB\n",
      "\n",
      "Results for yago2, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 17.79s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9942, MAE = 7168.02, MAPE = 1096.71%\n",
      "q-score: 13.11\n",
      "Prediction time: 12.7422 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000003\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 5117.80 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 4755.05 KB\n",
      "\n",
      "Results for yago2, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 3.48s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9688, MAE = 17169.37, MAPE = 6664.54%\n",
      "q-score: 74.21\n",
      "Prediction time: 9.3424 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.002061\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 5117.80 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 2453.35 KB\n",
      "\n",
      "Results for yago2, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 1.76s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9376, MAE = 24441.97, MAPE = 12438.46%\n",
      "q-score: 137.70\n",
      "Prediction time: 8.0201 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000007\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 5117.80 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 533.58 KB\n",
      "\n",
      "Results for yago2, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.43s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.8202, MAE = 43528.90, MAPE = 48059.57%\n",
      "q-score: 528.90\n",
      "Prediction time: 5.6282 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for yago2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 5117.80 MB\n",
      "\n",
      "Processing dataset: powerthingnodesorted\n",
      "Universe boundaries for powerthingnodesorted: (-177.92741900000001, -77.8453164, 178.47197400000002, 78.2256315)\n",
      "Loading data from ../large_files/resultsContains/powerthingnodesorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing MBR coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for powerthingnodesorted dataset:\n",
      "Max count: 10512575.0\n",
      "Min count: 0.0\n",
      "Mean count: 174964.97\n",
      "Median count: 41.00\n",
      "Total samples: 2102514\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1682011\n",
      "\n",
      "Training with sample size: 1682011\n",
      "Memory usage: 5119.80 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 1731.26s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 412494.78 KB\n",
      "\n",
      "Results for powerthingnodesorted, Sample Size: 1682011\n",
      "Grid Search Time: 1731.26s, Training Time: 1079.64s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9996, MAE = 3626.45, MAPE = 70.87%\n",
      "q-score: 2.24\n",
      "Prediction time: 30.2495 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000000\n",
      "Memory usage: 6208.62 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 250520.33 KB\n",
      "\n",
      "Results for powerthingnodesorted, Sample Size: 1000000\n",
      "Grid Search Time: 0.00s, Training Time: 582.70s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9994, MAE = 4414.30, MAPE = 109.22%\n",
      "q-score: 2.88\n",
      "Prediction time: 25.9314 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 500000\n",
      "Memory usage: 5178.50 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 129276.92 KB\n",
      "\n",
      "Results for powerthingnodesorted, Sample Size: 500000\n",
      "Grid Search Time: 0.00s, Training Time: 275.93s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9992, MAE = 5434.37, MAPE = 212.09%\n",
      "q-score: 4.65\n",
      "Prediction time: 20.3984 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 5178.50 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 28145.17 KB\n",
      "\n",
      "Results for powerthingnodesorted, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 37.17s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9967, MAE = 11023.86, MAPE = 1212.69%\n",
      "q-score: 21.36\n",
      "Prediction time: 10.5524 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000707\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 5178.50 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 14712.89 KB\n",
      "\n",
      "Results for powerthingnodesorted, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 18.07s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9943, MAE = 15208.25, MAPE = 2663.58%\n",
      "q-score: 45.40\n",
      "Prediction time: 8.8275 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 5178.50 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 3353.24 KB\n",
      "\n",
      "Results for powerthingnodesorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 3.34s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9745, MAE = 36093.96, MAPE = 21541.38%\n",
      "q-score: 352.73\n",
      "Prediction time: 6.8629 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 5178.50 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 1776.25 KB\n",
      "\n",
      "Results for powerthingnodesorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 1.67s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9364, MAE = 56514.19, MAPE = 41941.10%\n",
      "q-score: 684.94\n",
      "Prediction time: 6.2011 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 5178.50 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 409.63 KB\n",
      "\n",
      "Results for powerthingnodesorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.46s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.6780, MAE = 117322.96, MAPE = 135309.22%\n",
      "q-score: 2211.44\n",
      "Prediction time: 4.7664 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for powerthingnodesorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 5178.50 MB\n",
      "\n",
      "Processing dataset: emergencythingwaysorted\n",
      "Universe boundaries for emergencythingwaysorted: (-175.221337, -53.7941359, 179.3313189, 78.22019230000001)\n",
      "Loading data from ../large_files/resultsContains/emergencythingwaysorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing MBR coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for emergencythingwaysorted dataset:\n",
      "Max count: 807533.0\n",
      "Min count: 0.0\n",
      "Mean count: 13253.75\n",
      "Median count: 15.00\n",
      "Total samples: 161514\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 129211\n",
      "\n",
      "Training with sample size: 129211\n",
      "Memory usage: 5180.47 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 82.20s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 32386.34 KB\n",
      "\n",
      "Results for emergencythingwaysorted, Sample Size: 129211\n",
      "Grid Search Time: 82.20s, Training Time: 50.74s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9984, MAE = 468.70, MAPE = 57.32%\n",
      "q-score: 2.01\n",
      "Prediction time: 18.7084 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000015\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n",
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 5179.51 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 25611.35 KB\n",
      "\n",
      "Results for emergencythingwaysorted, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 37.38s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9982, MAE = 518.07, MAPE = 66.40%\n",
      "q-score: 2.15\n",
      "Prediction time: 18.2415 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 5179.51 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 13539.99 KB\n",
      "\n",
      "Results for emergencythingwaysorted, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 17.86s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9962, MAE = 777.00, MAPE = 133.24%\n",
      "q-score: 3.23\n",
      "Prediction time: 16.2030 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 5179.51 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 3160.63 KB\n",
      "\n",
      "Results for emergencythingwaysorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 3.22s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9850, MAE = 2062.02, MAPE = 572.05%\n",
      "q-score: 9.59\n",
      "Prediction time: 13.6884 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 5179.51 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 1713.41 KB\n",
      "\n",
      "Results for emergencythingwaysorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 1.68s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9695, MAE = 3224.94, MAPE = 1173.93%\n",
      "q-score: 18.28\n",
      "Prediction time: 12.8972 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 5179.51 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 390.61 KB\n",
      "\n",
      "Results for emergencythingwaysorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.49s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.7169, MAE = 9314.09, MAPE = 3587.32%\n",
      "q-score: 53.65\n",
      "Prediction time: 10.7223 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for emergencythingwaysorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 5179.51 MB\n",
      "\n",
      "Processing dataset: historicthingwaysorted\n",
      "Universe boundaries for historicthingwaysorted: (-179.99526020000002, -85.0036942, 179.99597930000002, 78.06750650000001)\n",
      "Loading data from ../large_files/resultsContains/historicthingwaysorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing MBR coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for historicthingwaysorted dataset:\n",
      "Max count: 1792176.0\n",
      "Min count: 0.0\n",
      "Mean count: 29764.89\n",
      "Median count: 16.00\n",
      "Total samples: 358439\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 286751\n",
      "\n",
      "Training with sample size: 286751\n",
      "Memory usage: 5181.49 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 194.00s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 67231.81 KB\n",
      "\n",
      "Results for historicthingwaysorted, Sample Size: 286751\n",
      "Grid Search Time: 194.00s, Training Time: 115.91s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9992, MAE = 830.13, MAPE = 37.24%\n",
      "q-score: 1.67\n",
      "Prediction time: 17.5956 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000004\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n",
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 5180.50 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 25620.69 KB\n",
      "\n",
      "Results for historicthingwaysorted, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 36.94s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9983, MAE = 1256.23, MAPE = 77.74%\n",
      "q-score: 2.35\n",
      "Prediction time: 13.7361 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000003\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 5180.50 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 13558.54 KB\n",
      "\n",
      "Results for historicthingwaysorted, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 18.59s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9973, MAE = 1678.71, MAPE = 135.04%\n",
      "q-score: 3.27\n",
      "Prediction time: 11.5913 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 5180.50 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 3101.05 KB\n",
      "\n",
      "Results for historicthingwaysorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 3.13s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9903, MAE = 3850.53, MAPE = 710.81%\n",
      "q-score: 11.61\n",
      "Prediction time: 8.9774 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000015\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 5180.50 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 1685.98 KB\n",
      "\n",
      "Results for historicthingwaysorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 1.57s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9789, MAE = 5933.65, MAPE = 1287.10%\n",
      "q-score: 19.92\n",
      "Prediction time: 8.8614 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 5180.50 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 379.50 KB\n",
      "\n",
      "Results for historicthingwaysorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.43s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.7805, MAE = 20984.07, MAPE = 10109.85%\n",
      "q-score: 146.03\n",
      "Prediction time: 6.7904 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.002123\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for historicthingwaysorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 5180.50 MB\n",
      "\n",
      "Processing dataset: aerowaythingwaysorted\n",
      "Universe boundaries for aerowaythingwaysorted: (-179.88131460000002, -79.7773063, 179.426138, 85.05258450000001)\n",
      "Loading data from ../large_files/resultsContains/aerowaythingwaysorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing MBR coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for aerowaythingwaysorted dataset:\n",
      "Max count: 1841551.0\n",
      "Min count: 0.0\n",
      "Mean count: 32184.18\n",
      "Median count: 226.00\n",
      "Total samples: 368365\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 294692\n",
      "\n",
      "Training with sample size: 294692\n",
      "Memory usage: 5182.45 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 213.80s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 85882.24 KB\n",
      "\n",
      "Results for aerowaythingwaysorted, Sample Size: 294692\n",
      "Grid Search Time: 213.80s, Training Time: 123.80s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9988, MAE = 1261.16, MAPE = 91.08%\n",
      "q-score: 2.36\n",
      "Prediction time: 22.0862 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000005\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 5181.48 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 31119.83 KB\n",
      "\n",
      "Results for aerowaythingwaysorted, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 40.08s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9973, MAE = 2026.05, MAPE = 170.88%\n",
      "q-score: 3.48\n",
      "Prediction time: 14.9629 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 5181.49 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 16213.92 KB\n",
      "\n",
      "Results for aerowaythingwaysorted, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 16.98s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9953, MAE = 2769.79, MAPE = 289.65%\n",
      "q-score: 5.08\n",
      "Prediction time: 12.7607 μs/sample\n",
      "I/O: Reads=0.000001, Writes=0.002621\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 5181.49 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 3678.60 KB\n",
      "\n",
      "Results for aerowaythingwaysorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 3.32s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9800, MAE = 6229.85, MAPE = 1078.91%\n",
      "q-score: 14.75\n",
      "Prediction time: 10.3435 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000004\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 5181.49 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 1969.54 KB\n",
      "\n",
      "Results for aerowaythingwaysorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 1.65s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9511, MAE = 9515.22, MAPE = 1911.14%\n",
      "q-score: 25.24\n",
      "Prediction time: 9.7224 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 5181.49 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 444.18 KB\n",
      "\n",
      "Results for aerowaythingwaysorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.49s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.8047, MAE = 19562.19, MAPE = 5287.46%\n",
      "q-score: 63.85\n",
      "Prediction time: 7.1485 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for aerowaythingwaysorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 5181.49 MB\n",
      "\n",
      "Processing dataset: arealm\n",
      "Universe boundaries for arealm: (-179.147236, -14.548699, 179.77847, 71.359879)\n",
      "Loading data from ../large_files/resultsContains/arealm_results.csv\n",
      "Parsing MBR coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for arealm dataset:\n",
      "Max count: 129097.0\n",
      "Min count: 0.0\n",
      "Mean count: 2282.26\n",
      "Median count: 0.00\n",
      "Total samples: 25833\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 20666\n",
      "\n",
      "Training with sample size: 20666\n",
      "Memory usage: 5180.71 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 473.98s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 11315.31 KB\n",
      "\n",
      "Results for arealm, Sample Size: 20666\n",
      "Grid Search Time: 473.98s, Training Time: 17.44s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9943, MAE = 170.85, MAPE = 41.98%\n",
      "q-score: 3.45\n",
      "Prediction time: 71.4482 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n",
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 5191.05 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 5858.78 KB\n",
      "\n",
      "Results for arealm, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 8.58s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9844, MAE = 276.16, MAPE = 78.88%\n",
      "q-score: 5.10\n",
      "Prediction time: 65.6935 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.004548\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 5191.07 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 3238.61 KB\n",
      "\n",
      "Results for arealm, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 4.40s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9759, MAE = 346.86, MAPE = 107.34%\n",
      "q-score: 7.33\n",
      "Prediction time: 61.8572 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000194\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 5191.07 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 779.84 KB\n",
      "\n",
      "Results for arealm, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 1.76s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.8190, MAE = 1111.26, MAPE = 1197.66%\n",
      "q-score: 69.30\n",
      "Prediction time: 54.5244 μs/sample\n",
      "I/O: Reads=0.001103, Writes=0.000058\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results for arealm...\n",
      "Saving combined results...\n",
      "All processing completed and results saved.\n",
      "Memory usage: 5191.07 MB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from time import process_time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import psutil\n",
    "import os\n",
    "import re\n",
    "import multiprocessing\n",
    "import joblib\n",
    "import gc\n",
    "from tqdm.notebook import tqdm  # Progress bars for Jupyter\n",
    "\n",
    "# Configuration options\n",
    "VISUALIZE_RECTANGLES = False  # Set to True if you want to visualize rectangles\n",
    "SAVE_INTERMEDIATE_MODELS = True  # Set to False to save only final models\n",
    "\n",
    "# Flag to control whether to use multiple scales or only the maximum scale\n",
    "use_multiple_scales = True  # Set to False to use only maximum scale, True for all scales\n",
    "\n",
    "# Get available CPU cores and set appropriate parallelism\n",
    "n_cores = multiprocessing.cpu_count()\n",
    "n_jobs = max(1, n_cores - 1)  # Leave one core free for system processes\n",
    "print(f\"Using {n_jobs} of {n_cores} available CPU cores\")\n",
    "\n",
    "def monitor_memory():\n",
    "    \"\"\"Print current memory usage of the process\"\"\"\n",
    "    process = psutil.Process()\n",
    "    memory_mb = process.memory_info().rss / (1024 * 1024)\n",
    "    print(f\"Memory usage: {memory_mb:.2f} MB\")\n",
    "\n",
    "def MAPE(actual_values, predicted_values):\n",
    "    \"\"\"Calculate Mean Absolute Percentage Error with special handling for zeros\"\"\"\n",
    "    # Vectorized implementation\n",
    "    actual_flat = actual_values.flatten()\n",
    "    pred_flat = predicted_values.flatten()\n",
    "    \n",
    "    # Create mask for non-zero actual values\n",
    "    non_zero_mask = actual_flat != 0\n",
    "    zero_mask = ~non_zero_mask\n",
    "    \n",
    "    # Calculate MAPE for non-zero elements\n",
    "    mape_sum = 0\n",
    "    count = len(actual_flat)\n",
    "    \n",
    "    if np.any(non_zero_mask):\n",
    "        mape_sum += np.sum(np.abs((actual_flat[non_zero_mask] - pred_flat[non_zero_mask]) / actual_flat[non_zero_mask]))\n",
    "    \n",
    "    if np.any(zero_mask):\n",
    "        mape_sum += np.sum(np.abs(actual_flat[zero_mask] - pred_flat[zero_mask]) / 100)\n",
    "    \n",
    "    return mape_sum / count\n",
    "\n",
    "# Load spatial statistics to get universe boundaries for each dataset\n",
    "print(\"Loading spatial statistics...\")\n",
    "spatial_stats = pd.read_csv('../spatial_statistics.csv')\n",
    "\n",
    "# Directory containing the datasets\n",
    "data_dir = '../large_files/resultsContains/'\n",
    "\n",
    "# Parse bounding box information\n",
    "def parse_bbox(bbox_str):\n",
    "    # Extract coordinates from BOX string using regex\n",
    "    pattern = r\"BOX\\(([-\\d\\.]+) ([-\\d\\.]+),([-\\d\\.]+) ([-\\d\\.]+)\\)\"\n",
    "    match = re.search(pattern, bbox_str)\n",
    "    if match:\n",
    "        xmin = float(match.group(1))\n",
    "        ymin = float(match.group(2))\n",
    "        xmax = float(match.group(3))\n",
    "        ymax = float(match.group(4))\n",
    "        return xmin, ymin, xmax, ymax\n",
    "    return -180, -90, 180, 90  # Default if parsing fails\n",
    "\n",
    "# Extract universe boundaries for each dataset\n",
    "universe_boundaries = {}\n",
    "for _, row in spatial_stats.iterrows():\n",
    "    table_name = row['Table Name']\n",
    "    bbox = parse_bbox(row['Universe Limits (Bounding Box)'])\n",
    "    universe_boundaries[table_name] = bbox\n",
    "\n",
    "# Get list of all CSV files in the directory\n",
    "print(\"Finding dataset files...\")\n",
    "csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "print(f\"Found {len(csv_files)} datasets to process\")\n",
    "\n",
    "# Define the scales of learning\n",
    "scales = [1000, 5000, 10000, 50000, 100000, 500000, 1000000]\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs('../large_files/LearnedModels/contain/RF', exist_ok=True)\n",
    "os.makedirs('../large_files/LearnedModels/contain/RF/visualizations', exist_ok=True)\n",
    "os.makedirs('../large_files/LearnedModels/contain/RF/results', exist_ok=True)\n",
    "\n",
    "# Lists to store all results\n",
    "all_results_list = []\n",
    "\n",
    "# Process each dataset\n",
    "for csv_file in tqdm(csv_files, desc=\"Processing datasets\"):\n",
    "    # Force garbage collection at the start of each dataset\n",
    "    gc.collect()\n",
    "    monitor_memory()\n",
    "    \n",
    "    # Extract dataset name (remove \"_results.csv\")\n",
    "    dataset_name = csv_file.replace('_results.csv', '')\n",
    "    \n",
    "    print(f\"\\nProcessing dataset: {dataset_name}\")\n",
    "    \n",
    "    # Get universe boundaries for this dataset\n",
    "    if dataset_name in universe_boundaries:\n",
    "        univ_xmin, univ_ymin, univ_xmax, univ_ymax = universe_boundaries[dataset_name]\n",
    "    else:\n",
    "        # Default values if dataset not found in spatial stats\n",
    "        univ_xmin, univ_ymin, univ_xmax, univ_ymax = -180, -90, 180, 90\n",
    "    \n",
    "    Surface_univ = (univ_xmax - univ_xmin) * (univ_ymax - univ_ymin)\n",
    "    print(f\"Universe boundaries for {dataset_name}: ({univ_xmin}, {univ_ymin}, {univ_xmax}, {univ_ymax})\")\n",
    "    \n",
    "    # Load dataset - only load required columns\n",
    "    data_path = os.path.join(data_dir, csv_file)\n",
    "    print(f\"Loading data from {data_path}\")\n",
    "    data = pd.read_csv(data_path, usecols=['Query MBR', 'Count MBR'])\n",
    "    \n",
    "    # Extract query MBR column (needs parsing as it's in string format)\n",
    "    def parse_mbr(mbr_str):\n",
    "        coords = mbr_str.strip('\"()').split(', ')\n",
    "        return [float(coord) for coord in coords]\n",
    "    \n",
    "    # Extract columns - use list comprehension for better performance\n",
    "    print(\"Parsing MBR coordinates...\")\n",
    "    Rectangles = np.array([parse_mbr(mbr) for mbr in data['Query MBR']])\n",
    "    Y = data[['Count MBR']].values  # Using Count MBR as target\n",
    "    \n",
    "    # Free up memory\n",
    "    del data\n",
    "    gc.collect()\n",
    "    \n",
    "    # Calculate basic statistics\n",
    "    max_count = float(np.max(Y))\n",
    "    min_count = float(np.min(Y))\n",
    "    mean_count = float(np.mean(Y))\n",
    "    median_count = float(np.median(Y))\n",
    "    total_samples = len(Y)\n",
    "\n",
    "    # Display basic statistics for the dataset\n",
    "    print(f\"\\nBasic statistics for {dataset_name} dataset:\")\n",
    "    print(f\"Max count: {max_count}\")\n",
    "    print(f\"Min count: {min_count}\")\n",
    "    print(f\"Mean count: {mean_count:.2f}\")\n",
    "    print(f\"Median count: {median_count:.2f}\")\n",
    "    print(f\"Total samples: {total_samples}\\n\")\n",
    "\n",
    "    # Calculate rectangles density - vectorized version\n",
    "    print(\"Calculating rectangle densities...\")\n",
    "    width = Rectangles[:, 2] - Rectangles[:, 0]\n",
    "    height = Rectangles[:, 3] - Rectangles[:, 1]\n",
    "    rectanglesDensity = np.abs(width * height / Surface_univ).reshape(-1, 1)\n",
    "    \n",
    "    # Prepare the dataset\n",
    "    # X = np.append(Rectangles, rectanglesDensity, axis=1)\n",
    "    X = Rectangles\n",
    "    \n",
    "    # Split the data into 80% train and 20% test\n",
    "    print(\"Splitting data into train and test sets...\")\n",
    "    X_train, X_test_all, y_train, y_test_all = train_test_split(X, Y, test_size=0.2, random_state=3)\n",
    "    \n",
    "    # Visualize the first 1000 rectangles (only if enabled)\n",
    "    if len(Rectangles) > 0 and VISUALIZE_RECTANGLES:\n",
    "        print(\"Visualizing rectangles sample...\")\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        ax = plt.subplot()\n",
    "        \n",
    "        # Only visualize a sample to save time\n",
    "        sample_size = min(1000, len(Rectangles))\n",
    "        for i in range(sample_size):\n",
    "            x1, y1, x2, y2 = Rectangles[i]\n",
    "            color_val = float(rectanglesDensity[i][0]) if hasattr(rectanglesDensity[i], '__len__') else float(rectanglesDensity[i])\n",
    "            rectangle = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, \n",
    "                                        linewidth=1, edgecolor='b', facecolor='none', alpha=min(1.0, color_val*10))\n",
    "            ax.add_patch(rectangle)\n",
    "            \n",
    "        plt.xlim(univ_xmin-20, univ_xmax+20)\n",
    "        plt.ylim(univ_ymin-10, univ_ymax+10)\n",
    "        plt.title(f\"Sample rectangles from {dataset_name}\")\n",
    "        plt.savefig(f\"../large_files/LearnedModels/contain/RF/visualizations/{dataset_name}_rectangles.png\", dpi=150)\n",
    "        plt.close()  # Close to free memory instead of plt.show()\n",
    "    \n",
    "    # Adjust scales to the dataset size\n",
    "    max_size = len(X_train)\n",
    "    print(f\"Training set size: {max_size}\")\n",
    "\n",
    "    if use_multiple_scales:\n",
    "        # Use multiple scales as before\n",
    "        adjusted_scales = [s for s in scales if s <= max_size]\n",
    "        \n",
    "        # Add intermediate 1 million increments for large datasets\n",
    "        if max_size > 1000000:\n",
    "            million_increments = list(range(2000000, max_size, 1000000))\n",
    "            adjusted_scales.extend(million_increments)\n",
    "            \n",
    "        # Add the actual max size if it's not already in the list\n",
    "        if max_size not in adjusted_scales:\n",
    "            adjusted_scales.append(max_size)\n",
    "            \n",
    "        # Sort the scales to ensure they're in ascending order\n",
    "        adjusted_scales.sort()\n",
    "    else:\n",
    "        # Use only the maximum scale\n",
    "        adjusted_scales = [max_size]\n",
    "\n",
    "    # List to store dataset-specific results\n",
    "    dataset_results_list = []\n",
    "\n",
    "    # Store best parameters from max scale training to reuse\n",
    "    best_params = None\n",
    "    \n",
    "    # Process scales in reversed order (largest first)\n",
    "    for sample_size in reversed(adjusted_scales):\n",
    "        print(f\"\\nTraining with sample size: {sample_size}\")\n",
    "        monitor_memory()\n",
    "        \n",
    "        # Create training subset\n",
    "        X_train_sample = X_train[:sample_size, :]\n",
    "        y_train_sample = y_train[:sample_size]\n",
    "        \n",
    "        # Random Forest Regressor parameters - optimized for performance\n",
    "        params_rf = {\n",
    "            \"n_estimators\": [50, 100, 200],\n",
    "            \"max_depth\": [10, 20, 30, None],\n",
    "            \"min_samples_split\": [2, 5, 10]\n",
    "        }\n",
    "        \n",
    "        # For very large datasets, use smaller parameter grid\n",
    "        if sample_size > 100000:\n",
    "            params_rf = {\n",
    "                \"n_estimators\": [50],\n",
    "                \"max_depth\": [None],\n",
    "                \"min_samples_split\": [5]\n",
    "            }\n",
    "            \n",
    "        # Only do GridSearch for the max scale\n",
    "        if sample_size == max_size or best_params is None:\n",
    "            print(\"Performing grid search for optimal parameters...\")\n",
    "            # Use a smaller max_features value to reduce memory usage\n",
    "            rf = RandomForestRegressor(random_state=3, max_features='sqrt', n_jobs=n_jobs)\n",
    "            rf_cv = GridSearchCV(rf, params_rf, cv=3, n_jobs=1, verbose=1)  # Use n_jobs=1 here as RF already uses parallelism\n",
    "            \n",
    "            # Time the grid search\n",
    "            t1_start = process_time()\n",
    "            rf_cv.fit(X_train_sample, y_train_sample.ravel())  # Use ravel for 1D array\n",
    "            t1_stop = process_time()\n",
    "            grid_search_time = t1_stop - t1_start\n",
    "            \n",
    "            # Store best parameters for reuse\n",
    "            best_params = rf_cv.best_params_\n",
    "            print(f\"Grid search complete in {grid_search_time:.2f}s\")\n",
    "            print(f\"Best parameters: {best_params}\")\n",
    "        else:\n",
    "            # Skip grid search for smaller scales, use params from max scale\n",
    "            rf_cv = None\n",
    "            grid_search_time = 0\n",
    "            print(f\"Using best parameters from max scale: {best_params}\")\n",
    "        \n",
    "        # Train the model with best parameters\n",
    "        print(\"Training random forest model...\")\n",
    "        rf = RandomForestRegressor(random_state=3, **best_params, n_jobs=n_jobs)\n",
    "        t2_start = process_time()\n",
    "        rf.fit(X_train_sample, y_train_sample.ravel())  # Use ravel for 1D array\n",
    "        t2_stop = process_time()\n",
    "        training_time = t2_stop - t2_start\n",
    "        \n",
    "        # Make predictions\n",
    "        print(\"Making predictions...\")\n",
    "        y_pred = rf.predict(X_test_all).reshape(-1, 1)  # Reshape to match y_test_all format\n",
    "        \n",
    "        # Calculate metrics\n",
    "        r2_score = rf.score(X_test_all, y_test_all.ravel())\n",
    "        mae_value = MAE(y_test_all, y_pred)\n",
    "        mape_value = MAPE(y_test_all, y_pred)\n",
    "        \n",
    "        # Calculate q-score - vectorized version\n",
    "        print(\"Calculating performance metrics...\")\n",
    "        \n",
    "        # Vectorized q-score calculation\n",
    "        y_true_flat = y_test_all.flatten()\n",
    "        y_pred_flat = y_pred.flatten() if y_pred.ndim > 1 else y_pred\n",
    "        \n",
    "        # Find indices where both values are non-zero\n",
    "        valid_indices = (y_true_flat != 0) & (y_pred_flat != 0)\n",
    "        \n",
    "        if np.any(valid_indices):\n",
    "            ratios = np.maximum(\n",
    "                y_pred_flat[valid_indices] / y_true_flat[valid_indices],\n",
    "                y_true_flat[valid_indices] / y_pred_flat[valid_indices]\n",
    "            )\n",
    "            q_score_mean = np.mean(ratios)\n",
    "        else:\n",
    "            q_score_mean = 0\n",
    "        \n",
    "        # Time prediction performance (10 iterations)\n",
    "        print(\"Measuring prediction performance...\")\n",
    "        total_duration = 0\n",
    "        total_read = 0\n",
    "        total_write = 0\n",
    "        \n",
    "        for _ in range(10):\n",
    "            io_before = psutil.disk_io_counters()\n",
    "            t3_start = process_time()\n",
    "            rf.predict(X_test_all)\n",
    "            t3_stop = process_time()\n",
    "            io_after = psutil.disk_io_counters()\n",
    "            \n",
    "            total_duration += (t3_stop - t3_start)\n",
    "            total_read += io_after.read_count - io_before.read_count\n",
    "            total_write += io_after.write_count - io_before.write_count\n",
    "        \n",
    "        avg_pred_time_microsec = (total_duration / 10) / len(y_pred) * 1000000\n",
    "        avg_reads = total_read / 10 / len(y_pred)\n",
    "        avg_writes = total_write / 10 / len(y_pred)\n",
    "        \n",
    "        # Save the model using joblib instead of pickle for better efficiency\n",
    "        if SAVE_INTERMEDIATE_MODELS or sample_size == max_size:\n",
    "            print(\"Saving model...\")\n",
    "            filename = f'../large_files/LearnedModels/contain/RF/{dataset_name}_rf_{sample_size}_{training_time:.2f}s_{mape_value:.2%}_{mae_value:.2f}.joblib'\n",
    "            joblib.dump(rf, filename, compress=3)\n",
    "            # Get model file size in KB\n",
    "            model_size_kb = os.path.getsize(filename) / 1024\n",
    "            print(f\"Model size: {model_size_kb:.2f} KB\")\n",
    "        else:\n",
    "            model_size_kb = 0  # Set to 0 if model wasn't saved\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\nResults for {dataset_name}, Sample Size: {sample_size}\")\n",
    "        print(f\"Grid Search Time: {grid_search_time:.2f}s, Training Time: {training_time:.2f}s\")\n",
    "        print(f\"Random Forest Parameters: {best_params}\")\n",
    "        print(f\"Performance: R² = {r2_score:.4f}, MAE = {mae_value:.2f}, MAPE = {mape_value:.2%}\")\n",
    "        print(f\"q-score: {q_score_mean:.2f}\")\n",
    "        print(f\"Prediction time: {avg_pred_time_microsec:.4f} μs/sample\")\n",
    "        print(f\"I/O: Reads={avg_reads:.6f}, Writes={avg_writes:.6f}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Plot actual vs predicted only for the maximum scale\n",
    "        if sample_size == adjusted_scales[-1]:  # Check if this is the maximum scale\n",
    "            print(\"Generating prediction scatter plot...\")\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.scatter(y_test_all, y_pred, s=0.5, alpha=0.5)\n",
    "            plt.xlabel('True Values')\n",
    "            plt.ylabel('Predictions')\n",
    "            plt.title(f\"{dataset_name} - Sample Size: {sample_size} (Maximum)\")\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add diagonal line for perfect predictions\n",
    "            max_val = max(np.max(y_test_all), np.max(y_pred))\n",
    "            plt.plot([0, max_val], [0, max_val], 'r--', alpha=0.5)\n",
    "            \n",
    "            plt.savefig(f\"../large_files/LearnedModels/contain/RF/visualizations/{dataset_name}_{sample_size}_prediction.png\", dpi=150)\n",
    "            plt.close()  # Close to free memory\n",
    "            \n",
    "            # Create a scatter plot comparing predicted vs real values for first 100 rectangles\n",
    "            print(\"Generating side-by-side comparison plot...\")\n",
    "            \n",
    "            # Get predictions for first 100 test samples\n",
    "            sample_indices = range(min(100, len(X_test_all)))\n",
    "            X_sample = X_test_all[sample_indices]\n",
    "            y_sample_true = y_test_all[sample_indices].flatten()\n",
    "            y_sample_pred = rf.predict(X_sample)\n",
    "            \n",
    "            plt.figure(figsize=(20, 10))\n",
    "            plt.scatter(range(len(sample_indices)), y_sample_pred, c='blue', \n",
    "                        label='Predicted number of objects (Random Forest)', alpha=0.7, s=100)\n",
    "            plt.scatter(range(len(sample_indices)), y_sample_true, c='green', \n",
    "                        label='Real number of objects', alpha=0.7, s=100)\n",
    "            \n",
    "            plt.title(f'{dataset_name} - First {len(sample_indices)} Rectangles: Predicted vs Real Values', fontsize=16)\n",
    "            plt.xlabel('Rectangle Index', fontsize=14)\n",
    "            plt.ylabel('Number of objects in rectangle', fontsize=14)\n",
    "            plt.legend(fontsize=12)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save the plot\n",
    "            plt.savefig(f\"../large_files/LearnedModels/contain/RF/visualizations/{dataset_name}_comparison_plot.png\", dpi=150)\n",
    "            plt.close()\n",
    "        \n",
    "        # Store results in list (more efficient than DataFrame concat)\n",
    "        result_row = {\n",
    "            'Dataset': dataset_name,\n",
    "            'Sample_Size': sample_size,\n",
    "            'Training_Time': training_time,\n",
    "            'Best_Params': str(best_params),\n",
    "            'R2_Score': r2_score,\n",
    "            'MAE': mae_value,\n",
    "            'MAPE': float(mape_value),\n",
    "            'Q_Score': q_score_mean,\n",
    "            'Pred_Time_Microseconds': avg_pred_time_microsec,\n",
    "            'IO_Reads': avg_reads,\n",
    "            'IO_Writes': avg_writes,\n",
    "            'Model_Size_KB': model_size_kb,\n",
    "            'Max_Count': max_count,\n",
    "            'Min_Count': min_count,\n",
    "            'Mean_Count': mean_count,\n",
    "            'Median_Count': median_count,\n",
    "            'Total_Samples': total_samples\n",
    "        }\n",
    "        \n",
    "        dataset_results_list.append(result_row)\n",
    "        all_results_list.append(result_row)\n",
    "        \n",
    "        # Clean up to free memory\n",
    "        if sample_size != max_size:  # Don't delete for max size as we might need it\n",
    "            del X_train_sample, y_train_sample, rf\n",
    "            gc.collect()\n",
    "    \n",
    "    # Save results for this dataset\n",
    "    print(f\"Saving results for {dataset_name}...\")\n",
    "    dataset_results = pd.DataFrame(dataset_results_list)\n",
    "    dataset_results.to_csv(f'../large_files/LearnedModels/contain/RF/results/{dataset_name}_results.csv', index=False)\n",
    "    \n",
    "    # Clear memory before next dataset\n",
    "    del X_train, X_test_all, y_train, y_test_all, Rectangles, Y, rectanglesDensity\n",
    "    gc.collect()\n",
    "    \n",
    "# Save all results\n",
    "print(\"Saving combined results...\")\n",
    "all_results = pd.DataFrame(all_results_list)\n",
    "all_results.to_csv('../large_files/LearnedModels/contain/RF/all_results.csv', index=False)\n",
    "\n",
    "print(\"All processing completed and results saved.\")\n",
    "monitor_memory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2843.198635,
   "end_time": "2025-03-24T23:38:24.585542",
   "environment_variables": {},
   "exception": null,
   "input_path": "/home/adminlias/nadir/Spatial-Selectivity-Ext/contain_filter/randomForestRegressor.ipynb",
   "output_path": "/home/adminlias/nadir/Spatial-Selectivity-Ext/contain_filter/output_randomForestRegressor.ipynb",
   "parameters": {},
   "start_time": "2025-03-24T22:51:01.386907",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "02d9931cb7f14b94990452967d5e73b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e4253165019b4a9390a5956f4bd1e7a1",
        "IPY_MODEL_3d9214fd35b84da1a83870343009dd17",
        "IPY_MODEL_2ebb43f67a534a9d8e8025744bb10837"
       ],
       "layout": "IPY_MODEL_37051f2aa88e44dea39bca06e1ed35be"
      }
     },
     "1dba248b85c04f2c877c0d5819bb5689": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2ebb43f67a534a9d8e8025744bb10837": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_68081657c7a746e89396ed82370836d9",
       "placeholder": "​",
       "style": "IPY_MODEL_757861da12ee4500bf8b31672938dfe5",
       "value": " 14/14 [47:20&lt;00:00, 86.60s/it]"
      }
     },
     "37051f2aa88e44dea39bca06e1ed35be": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3d9214fd35b84da1a83870343009dd17": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6fa4c50aa10f4ef7b5d54e88e5880d91",
       "max": 14.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_95c023e91432427b9451551f6076f7cd",
       "value": 14.0
      }
     },
     "68081657c7a746e89396ed82370836d9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6fa4c50aa10f4ef7b5d54e88e5880d91": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "757861da12ee4500bf8b31672938dfe5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "95c023e91432427b9451551f6076f7cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e4253165019b4a9390a5956f4bd1e7a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1dba248b85c04f2c877c0d5819bb5689",
       "placeholder": "​",
       "style": "IPY_MODEL_fdd28a52b09940f19a4d992447eab777",
       "value": "Processing datasets: 100%"
      }
     },
     "fdd28a52b09940f19a4d992447eab777": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}