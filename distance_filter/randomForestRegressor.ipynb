{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b128611",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T08:17:21.477179Z",
     "iopub.status.busy": "2025-04-19T08:17:21.476565Z",
     "iopub.status.idle": "2025-04-19T09:40:03.599956Z",
     "shell.execute_reply": "2025-04-19T09:40:03.598894Z"
    },
    "papermill": {
     "duration": 4962.132379,
     "end_time": "2025-04-19T09:40:03.601374",
     "exception": false,
     "start_time": "2025-04-19T08:17:21.468995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 29 of 30 available CPU cores\n",
      "Loading spatial statistics...\n",
      "Finding dataset files...\n",
      "Found 14 datasets to process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125bea93c4e64ab7a0c4b4d20637ec3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing datasets:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 249.42 MB\n",
      "\n",
      "Processing dataset: craftwaysorted\n",
      "Universe boundaries for craftwaysorted: (-175.2000514, -65.2458821, 175.3397782, 69.6673353)\n",
      "Loading data from ../large_files/resultsDistance/craftwaysorted_results.csv\n",
      "Parsing object coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for craftwaysorted dataset:\n",
      "Max count: 100369.0\n",
      "Min count: 0.0\n",
      "Mean count: 11615.73\n",
      "Median count: 3842.00\n",
      "Total samples: 21822\n",
      "\n",
      "Calculating object features...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 17457\n",
      "\n",
      "Training with sample size: 17457\n",
      "Memory usage: 258.79 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 633.60s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 63614.89 KB\n",
      "\n",
      "Results for craftwaysorted, Sample Size: 17457\n",
      "Grid Search Time: 633.60s, Training Time: 53.72s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9199, MAE = 1787.10, MAPE = 182.73%\n",
      "q-score: 2.88\n",
      "Prediction time: 189.0582 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature importance plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 969.07 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 36830.16 KB\n",
      "\n",
      "Results for craftwaysorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 26.85s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.8992, MAE = 2088.24, MAPE = 187.63%\n",
      "q-score: 2.94\n",
      "Prediction time: 166.6527 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000092\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 523.79 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 18637.83 KB\n",
      "\n",
      "Results for craftwaysorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 13.83s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.8678, MAE = 2565.39, MAPE = 296.25%\n",
      "q-score: 4.04\n",
      "Prediction time: 142.7261 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000183\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 525.95 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 3876.04 KB\n",
      "\n",
      "Results for craftwaysorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 3.03s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.7665, MAE = 4096.17, MAPE = 620.62%\n",
      "q-score: 7.32\n",
      "Prediction time: 101.2341 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000115\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for craftwaysorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 525.98 MB\n",
      "\n",
      "Processing dataset: powerthingwaysorted\n",
      "Universe boundaries for powerthingwaysorted: (-179.5002188, -75.1012051, 178.4574038, 82.5247908)\n",
      "Loading data from ../large_files/resultsDistance/powerthingwaysorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing object coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for powerthingwaysorted dataset:\n",
      "Max count: 13577236.0\n",
      "Min count: 0.0\n",
      "Mean count: 885963.11\n",
      "Median count: 467788.00\n",
      "Total samples: 2717289\n",
      "\n",
      "Calculating object features...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into train and test sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 2173831\n",
      "\n",
      "Training with sample size: 2173831\n",
      "Memory usage: 1381.24 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 2563.49s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 1092076.78 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 2173831\n",
      "Grid Search Time: 2563.49s, Training Time: 2776.33s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9965, MAE = 27360.36, MAPE = 43.35%\n",
      "q-score: 1.38\n",
      "Prediction time: 56.5407 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000002\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature importance plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 2000000\n",
      "Memory usage: 11471.75 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 1005352.90 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 2000000\n",
      "Grid Search Time: 0.00s, Training Time: 2661.89s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9963, MAE = 28236.19, MAPE = 47.60%\n",
      "q-score: 1.42\n",
      "Prediction time: 55.5024 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000002\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000000\n",
      "Memory usage: 1955.23 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 505564.41 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 1000000\n",
      "Grid Search Time: 0.00s, Training Time: 1184.68s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9940, MAE = 35596.87, MAPE = 76.97%\n",
      "q-score: 1.67\n",
      "Prediction time: 47.0288 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000003\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 500000\n",
      "Memory usage: 2957.98 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 254323.41 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 500000\n",
      "Grid Search Time: 0.00s, Training Time: 545.21s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9905, MAE = 45032.54, MAPE = 104.88%\n",
      "q-score: 1.93\n",
      "Prediction time: 37.7854 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000002\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 3096.95 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 51656.26 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 74.26s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9730, MAE = 76966.73, MAPE = 181.04%\n",
      "q-score: 2.59\n",
      "Prediction time: 17.3165 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 3096.95 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 26013.98 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 33.34s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9615, MAE = 95036.39, MAPE = 236.65%\n",
      "q-score: 3.07\n",
      "Prediction time: 11.7265 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 3096.95 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 5332.84 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 6.54s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9109, MAE = 157729.59, MAPE = 525.59%\n",
      "q-score: 5.84\n",
      "Prediction time: 8.2260 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.001064\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 3098.95 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 2705.20 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 2.73s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.8775, MAE = 190214.57, MAPE = 771.05%\n",
      "q-score: 8.13\n",
      "Prediction time: 7.1631 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 3098.95 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 564.12 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.60s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.7672, MAE = 279224.37, MAPE = 1549.40%\n",
      "q-score: 15.51\n",
      "Prediction time: 4.7558 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000002\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for powerthingwaysorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 2829.44 MB\n",
      "\n",
      "Processing dataset: barrierthingwaysorted\n",
      "Universe boundaries for barrierthingwaysorted: (-179.7595238, -70.776382, 179.19591350000002, 78.2501675)\n",
      "Loading data from ../large_files/resultsDistance/barrierthingwaysorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing object coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for barrierthingwaysorted dataset:\n",
      "Max count: 22854431.0\n",
      "Min count: 0.0\n",
      "Mean count: 2474469.83\n",
      "Median count: 1209323.00\n",
      "Total samples: 4581670\n",
      "\n",
      "Calculating object features...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into train and test sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 3665336\n",
      "\n",
      "Training with sample size: 3665336\n",
      "Memory usage: 3659.36 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 4747.31s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 1872693.45 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 3665336\n",
      "Grid Search Time: 4747.31s, Training Time: 5116.37s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9973, MAE = 61976.78, MAPE = 65.46%\n",
      "q-score: 1.61\n",
      "Prediction time: 65.3166 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000004\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature importance plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 3000000\n",
      "Memory usage: 18718.13 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 1535317.48 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 3000000\n",
      "Grid Search Time: 0.00s, Training Time: 4365.03s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9970, MAE = 65802.97, MAPE = 60.56%\n",
      "q-score: 1.56\n",
      "Prediction time: 61.8785 μs/sample\n",
      "I/O: Reads=0.000006, Writes=0.000003\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 2000000\n",
      "Memory usage: 5348.31 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 1027180.24 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 2000000\n",
      "Grid Search Time: 0.00s, Training Time: 2571.93s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9960, MAE = 75273.63, MAPE = 75.46%\n",
      "q-score: 1.70\n",
      "Prediction time: 56.2757 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000003\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000000\n",
      "Memory usage: 4937.55 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 516582.80 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 1000000\n",
      "Grid Search Time: 0.00s, Training Time: 1199.79s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9939, MAE = 93956.13, MAPE = 111.98%\n",
      "q-score: 2.05\n",
      "Prediction time: 47.5184 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000002\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 500000\n",
      "Memory usage: 5374.32 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 259651.50 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 500000\n",
      "Grid Search Time: 0.00s, Training Time: 534.74s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9903, MAE = 118364.53, MAPE = 173.16%\n",
      "q-score: 2.61\n",
      "Prediction time: 38.1970 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000002\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 5421.30 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 52724.78 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 80.77s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9714, MAE = 205032.86, MAPE = 395.60%\n",
      "q-score: 4.57\n",
      "Prediction time: 17.5143 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 5421.30 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 26519.17 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 38.43s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9598, MAE = 252495.71, MAPE = 640.85%\n",
      "q-score: 6.75\n",
      "Prediction time: 11.7632 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000002\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 5421.30 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 5421.27 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 6.68s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9027, MAE = 413817.89, MAPE = 1170.91%\n",
      "q-score: 11.39\n",
      "Prediction time: 8.2069 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 5421.30 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 2747.18 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 3.11s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.8822, MAE = 492828.60, MAPE = 1579.77%\n",
      "q-score: 15.21\n",
      "Prediction time: 6.9225 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 5421.30 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 576.78 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.69s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.7783, MAE = 775412.13, MAPE = 3277.70%\n",
      "q-score: 30.94\n",
      "Prediction time: 4.4458 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for barrierthingwaysorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 4966.88 MB\n",
      "\n",
      "Processing dataset: cyclewaythingwaysorted\n",
      "Universe boundaries for cyclewaythingwaysorted: (-175.2093065, -75.1027861, 176.92582230000002, 71.0488105)\n",
      "Loading data from ../large_files/resultsDistance/cyclewaythingwaysorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing object coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for cyclewaythingwaysorted dataset:\n",
      "Max count: 5317936.0\n",
      "Min count: 0.0\n",
      "Mean count: 503879.05\n",
      "Median count: 222046.00\n",
      "Total samples: 1067063\n",
      "\n",
      "Calculating object features...\n",
      "Splitting data into train and test sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 853650\n",
      "\n",
      "Training with sample size: 853650\n",
      "Memory usage: 4274.68 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 899.37s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 427842.65 KB\n",
      "\n",
      "Results for cyclewaythingwaysorted, Sample Size: 853650\n",
      "Grid Search Time: 899.37s, Training Time: 999.18s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9937, MAE = 20025.39, MAPE = 138.45%\n",
      "q-score: 2.25\n",
      "Prediction time: 46.7700 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature importance plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 500000\n",
      "Memory usage: 6356.19 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 252141.25 KB\n",
      "\n",
      "Results for cyclewaythingwaysorted, Sample Size: 500000\n",
      "Grid Search Time: 0.00s, Training Time: 540.45s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9908, MAE = 23988.01, MAPE = 166.61%\n",
      "q-score: 2.51\n",
      "Prediction time: 39.2594 μs/sample\n",
      "I/O: Reads=0.000028, Writes=0.000005\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 4326.27 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 51414.62 KB\n",
      "\n",
      "Results for cyclewaythingwaysorted, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 77.95s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9759, MAE = 41012.48, MAPE = 330.21%\n",
      "q-score: 3.89\n",
      "Prediction time: 18.3745 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 4328.23 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 25953.19 KB\n",
      "\n",
      "Results for cyclewaythingwaysorted, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 40.17s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9630, MAE = 51927.62, MAPE = 461.67%\n",
      "q-score: 5.09\n",
      "Prediction time: 12.8998 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000007\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 4328.23 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 5323.73 KB\n",
      "\n",
      "Results for cyclewaythingwaysorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 5.96s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9084, MAE = 85196.45, MAPE = 1025.89%\n",
      "q-score: 9.89\n",
      "Prediction time: 9.1727 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 4328.23 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 2710.78 KB\n",
      "\n",
      "Results for cyclewaythingwaysorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 2.86s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.8804, MAE = 103064.82, MAPE = 1363.99%\n",
      "q-score: 12.97\n",
      "Prediction time: 7.9441 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 4328.23 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 567.35 KB\n",
      "\n",
      "Results for cyclewaythingwaysorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.64s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.7891, MAE = 158544.22, MAPE = 2611.77%\n",
      "q-score: 24.51\n",
      "Prediction time: 5.3294 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for cyclewaythingwaysorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 4328.23 MB\n",
      "\n",
      "Processing dataset: zcta5\n",
      "Universe boundaries for zcta5: (-176.684744, -14.373776, 145.830505, 71.341324)\n",
      "Loading data from ../large_files/resultsDistance/zcta5_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing object coordinates...\n",
      "\n",
      "Basic statistics for zcta5 dataset:\n",
      "Max count: 31899.0\n",
      "Min count: 0.0\n",
      "Mean count: 5892.11\n",
      "Median count: 4178.50\n",
      "Total samples: 6626\n",
      "\n",
      "Calculating object features...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 5300\n",
      "\n",
      "Training with sample size: 5300\n",
      "Memory usage: 4265.43 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 257.47s\n",
      "Best parameters: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 19370.19 KB\n",
      "\n",
      "Results for zcta5, Sample Size: 5300\n",
      "Grid Search Time: 257.47s, Training Time: 15.89s\n",
      "Random Forest Parameters: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9576, MAE = 601.90, MAPE = 100.33%\n",
      "q-score: 1.88\n",
      "Prediction time: 245.0617 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature importance plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 4272.89 MB\n",
      "Using best parameters from max scale: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 18296.95 KB\n",
      "\n",
      "Results for zcta5, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 15.25s\n",
      "Random Forest Parameters: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9579, MAE = 608.67, MAPE = 107.42%\n",
      "q-score: 1.96\n",
      "Prediction time: 244.4647 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 4272.90 MB\n",
      "Using best parameters from max scale: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 3822.00 KB\n",
      "\n",
      "Results for zcta5, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 3.17s\n",
      "Random Forest Parameters: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9149, MAE = 948.60, MAPE = 204.24%\n",
      "q-score: 2.87\n",
      "Prediction time: 188.8030 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000452\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for zcta5...\n",
      "Memory usage: 4272.90 MB\n",
      "\n",
      "Processing dataset: aerowaythingnodesorted\n",
      "Universe boundaries for aerowaythingnodesorted: (-179.88088960000002, -90.0, 179.951004, 83.08333590000001)\n",
      "Loading data from ../large_files/resultsDistance/aerowaythingnodesorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing object coordinates...\n",
      "\n",
      "Basic statistics for aerowaythingnodesorted dataset:\n",
      "Max count: 74280.0\n",
      "Min count: 0.0\n",
      "Mean count: 4340.59\n",
      "Median count: 2002.00\n",
      "Total samples: 15843\n",
      "\n",
      "Calculating object features...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 12674\n",
      "\n",
      "Training with sample size: 12674\n",
      "Memory usage: 4272.90 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 434.95s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 45670.93 KB\n",
      "\n",
      "Results for aerowaythingnodesorted, Sample Size: 12674\n",
      "Grid Search Time: 434.95s, Training Time: 31.01s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9352, MAE = 720.30, MAPE = 137.25%\n",
      "q-score: 2.43\n",
      "Prediction time: 189.2304 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature importance plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 4278.90 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 36187.45 KB\n",
      "\n",
      "Results for aerowaythingnodesorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 27.02s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9283, MAE = 761.37, MAPE = 151.99%\n",
      "q-score: 2.58\n",
      "Prediction time: 181.5026 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 4278.90 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 18294.55 KB\n",
      "\n",
      "Results for aerowaythingnodesorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 12.41s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9014, MAE = 909.43, MAPE = 215.76%\n",
      "q-score: 3.23\n",
      "Prediction time: 159.0201 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 4278.90 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 3793.48 KB\n",
      "\n",
      "Results for aerowaythingnodesorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 2.83s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.8085, MAE = 1263.73, MAPE = 489.47%\n",
      "q-score: 5.99\n",
      "Prediction time: 118.1792 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for aerowaythingnodesorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 4278.90 MB\n",
      "\n",
      "Processing dataset: leisurewaysorted\n",
      "Universe boundaries for leisurewaysorted: (-179.8728244, -89.6957847, 179.8091866, 81.0280175)\n",
      "Loading data from ../large_files/resultsDistance/leisurewaysorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing object coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for leisurewaysorted dataset:\n",
      "Max count: 29357364.0\n",
      "Min count: 0.0\n",
      "Mean count: 2752172.81\n",
      "Median count: 1238338.00\n",
      "Total samples: 5876570\n",
      "\n",
      "Calculating object features...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into train and test sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 4701256\n",
      "\n",
      "Training with sample size: 4701256\n",
      "Memory usage: 4681.35 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 6303.06s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 2395613.94 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 4701256\n",
      "Grid Search Time: 6303.06s, Training Time: 6942.31s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9979, MAE = 63250.11, MAPE = 42.03%\n",
      "q-score: 1.39\n",
      "Prediction time: 67.5724 μs/sample\n",
      "I/O: Reads=0.000005, Writes=0.000004\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature importance plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 4000000\n",
      "Memory usage: 21844.59 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 2040806.76 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 4000000\n",
      "Grid Search Time: 0.00s, Training Time: 5719.56s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9976, MAE = 66805.86, MAPE = 50.25%\n",
      "q-score: 1.47\n",
      "Prediction time: 65.0944 μs/sample\n",
      "I/O: Reads=0.000005, Writes=0.000004\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 3000000\n",
      "Memory usage: 6153.56 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 1534110.80 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 3000000\n",
      "Grid Search Time: 0.00s, Training Time: 4209.67s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9971, MAE = 73006.82, MAPE = 56.58%\n",
      "q-score: 1.53\n",
      "Prediction time: 60.6853 μs/sample\n",
      "I/O: Reads=0.000005, Writes=0.000003\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 2000000\n",
      "Memory usage: 4719.46 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 1026019.95 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 2000000\n",
      "Grid Search Time: 0.00s, Training Time: 2564.25s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9962, MAE = 83378.81, MAPE = 74.37%\n",
      "q-score: 1.69\n",
      "Prediction time: 55.6102 μs/sample\n",
      "I/O: Reads=0.000005, Writes=0.000004\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000000\n",
      "Memory usage: 5018.61 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 515759.27 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 1000000\n",
      "Grid Search Time: 0.00s, Training Time: 1191.34s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9940, MAE = 104479.39, MAPE = 103.78%\n",
      "q-score: 1.92\n",
      "Prediction time: 46.7803 μs/sample\n",
      "I/O: Reads=0.000005, Writes=0.000003\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 500000\n",
      "Memory usage: 4780.35 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 259197.89 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 500000\n",
      "Grid Search Time: 0.00s, Training Time: 547.92s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9907, MAE = 128666.91, MAPE = 158.05%\n",
      "q-score: 2.36\n",
      "Prediction time: 37.4151 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000006\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 4789.17 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 52512.63 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 78.82s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9734, MAE = 221955.07, MAPE = 552.05%\n",
      "q-score: 5.96\n",
      "Prediction time: 17.2396 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 4789.31 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 26408.05 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 37.77s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9590, MAE = 283010.36, MAPE = 1057.27%\n",
      "q-score: 10.63\n",
      "Prediction time: 11.5487 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 4789.31 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 5397.71 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 6.82s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9050, MAE = 467540.00, MAPE = 3749.05%\n",
      "q-score: 36.53\n",
      "Prediction time: 7.9888 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 4789.31 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 2745.02 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 2.95s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.8789, MAE = 553029.07, MAPE = 4935.81%\n",
      "q-score: 47.61\n",
      "Prediction time: 6.7761 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 4789.31 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 571.70 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.64s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.7694, MAE = 800738.57, MAPE = 6881.07%\n",
      "q-score: 65.47\n",
      "Prediction time: 4.3398 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for leisurewaysorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 4394.77 MB\n",
      "\n",
      "Processing dataset: areawater\n",
      "Universe boundaries for areawater: (-179.231086, -14.601813, 179.859681, 71.441059)\n",
      "Loading data from ../large_files/resultsDistance/areawater_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing object coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for areawater dataset:\n",
      "Max count: 2292056.0\n",
      "Min count: 0.0\n",
      "Mean count: 483232.05\n",
      "Median count: 331295.00\n",
      "Total samples: 458552\n",
      "\n",
      "Calculating object features...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 366841\n",
      "\n",
      "Training with sample size: 366841\n",
      "Memory usage: 4399.71 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 373.03s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 180957.66 KB\n",
      "\n",
      "Results for areawater, Sample Size: 366841\n",
      "Grid Search Time: 373.03s, Training Time: 411.30s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9971, MAE = 14697.12, MAPE = 176.96%\n",
      "q-score: 2.61\n",
      "Prediction time: 35.0832 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature importance plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 4421.34 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 50042.46 KB\n",
      "\n",
      "Results for areawater, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 97.58s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9934, MAE = 22074.49, MAPE = 462.57%\n",
      "q-score: 5.10\n",
      "Prediction time: 18.5167 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000011\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 4405.34 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 25201.49 KB\n",
      "\n",
      "Results for areawater, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 44.86s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9900, MAE = 27461.78, MAPE = 1510.11%\n",
      "q-score: 15.33\n",
      "Prediction time: 14.4386 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 4405.34 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 5175.94 KB\n",
      "\n",
      "Results for areawater, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 7.15s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9757, MAE = 44765.93, MAPE = 6073.14%\n",
      "q-score: 60.29\n",
      "Prediction time: 10.6196 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 4405.34 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 2631.03 KB\n",
      "\n",
      "Results for areawater, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 3.28s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9590, MAE = 56884.77, MAPE = 7589.98%\n",
      "q-score: 75.29\n",
      "Prediction time: 9.5816 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000002\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 4405.34 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 556.77 KB\n",
      "\n",
      "Results for areawater, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.75s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.8945, MAE = 93563.91, MAPE = 11563.07%\n",
      "q-score: 114.95\n",
      "Prediction time: 7.0636 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for areawater...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 4405.34 MB\n",
      "\n",
      "Processing dataset: yago2\n",
      "Universe boundaries for yago2: (-179.98473, -90.0, 180.0, 90.0)\n",
      "Loading data from ../large_files/resultsDistance/yago2_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing object coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for yago2 dataset:\n",
      "Max count: 4470390.0\n",
      "Min count: 0.0\n",
      "Mean count: 279738.01\n",
      "Median count: 172925.00\n",
      "Total samples: 898942\n",
      "\n",
      "Calculating object features...\n",
      "Splitting data into train and test sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 719153\n",
      "\n",
      "Training with sample size: 719153\n",
      "Memory usage: 4410.31 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 741.10s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 362173.94 KB\n",
      "\n",
      "Results for yago2, Sample Size: 719153\n",
      "Grid Search Time: 741.10s, Training Time: 791.45s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9852, MAE = 14691.61, MAPE = 46.93%\n",
      "q-score: 1.36\n",
      "Prediction time: 44.1506 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature importance plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 500000\n",
      "Memory usage: 5822.65 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 252500.05 KB\n",
      "\n",
      "Results for yago2, Sample Size: 500000\n",
      "Grid Search Time: 0.00s, Training Time: 556.55s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9822, MAE = 16344.46, MAPE = 59.09%\n",
      "q-score: 1.45\n",
      "Prediction time: 39.4966 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000004\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 4369.20 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 51220.77 KB\n",
      "\n",
      "Results for yago2, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 86.76s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9631, MAE = 25944.65, MAPE = 133.13%\n",
      "q-score: 2.02\n",
      "Prediction time: 18.1174 μs/sample\n",
      "I/O: Reads=0.000033, Writes=0.000003\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 4369.20 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 25797.98 KB\n",
      "\n",
      "Results for yago2, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 41.88s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9510, MAE = 31151.40, MAPE = 140.95%\n",
      "q-score: 1.98\n",
      "Prediction time: 13.3800 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 4369.20 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 5301.90 KB\n",
      "\n",
      "Results for yago2, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 6.55s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9118, MAE = 45117.45, MAPE = 514.48%\n",
      "q-score: 4.65\n",
      "Prediction time: 9.4268 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 4369.20 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 2692.38 KB\n",
      "\n",
      "Results for yago2, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 3.39s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.8837, MAE = 53019.38, MAPE = 647.62%\n",
      "q-score: 5.52\n",
      "Prediction time: 8.2966 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 4369.20 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 563.82 KB\n",
      "\n",
      "Results for yago2, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.64s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.8246, MAE = 68501.18, MAPE = 857.62%\n",
      "q-score: 6.97\n",
      "Prediction time: 5.6013 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for yago2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 4369.20 MB\n",
      "\n",
      "Processing dataset: powerthingnodesorted\n",
      "Universe boundaries for powerthingnodesorted: (-177.92741900000001, -77.8453164, 178.47197400000002, 78.2256315)\n",
      "Loading data from ../large_files/resultsDistance/powerthingnodesorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing object coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for powerthingnodesorted dataset:\n",
      "Max count: 10461467.0\n",
      "Min count: 0.0\n",
      "Mean count: 665028.42\n",
      "Median count: 348182.50\n",
      "Total samples: 2102514\n",
      "\n",
      "Calculating object features...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into train and test sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1682011\n",
      "\n",
      "Training with sample size: 1682011\n",
      "Memory usage: 4375.11 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 1833.64s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 841069.00 KB\n",
      "\n",
      "Results for powerthingnodesorted, Sample Size: 1682011\n",
      "Grid Search Time: 1833.64s, Training Time: 1991.43s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9961, MAE = 21963.51, MAPE = 123.44%\n",
      "q-score: 2.20\n",
      "Prediction time: 53.5396 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000005\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature importance plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000000\n",
      "Memory usage: 9353.76 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 502109.92 KB\n",
      "\n",
      "Results for powerthingnodesorted, Sample Size: 1000000\n",
      "Grid Search Time: 0.00s, Training Time: 1065.51s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9946, MAE = 26005.03, MAPE = 168.52%\n",
      "q-score: 2.61\n",
      "Prediction time: 47.1062 μs/sample\n",
      "I/O: Reads=0.000014, Writes=0.000004\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 500000\n",
      "Memory usage: 4794.23 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 252482.90 KB\n",
      "\n",
      "Results for powerthingnodesorted, Sample Size: 500000\n",
      "Grid Search Time: 0.00s, Training Time: 484.97s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9917, MAE = 32466.31, MAPE = 237.19%\n",
      "q-score: 3.26\n",
      "Prediction time: 37.6654 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000002\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 4794.23 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 51246.13 KB\n",
      "\n",
      "Results for powerthingnodesorted, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 74.84s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9772, MAE = 54979.14, MAPE = 676.83%\n",
      "q-score: 7.48\n",
      "Prediction time: 17.3488 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 4794.23 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 25818.77 KB\n",
      "\n",
      "Results for powerthingnodesorted, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 34.29s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9663, MAE = 68377.10, MAPE = 931.64%\n",
      "q-score: 9.95\n",
      "Prediction time: 12.2664 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 4794.23 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 5269.64 KB\n",
      "\n",
      "Results for powerthingnodesorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 5.37s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9174, MAE = 113987.89, MAPE = 1777.18%\n",
      "q-score: 18.19\n",
      "Prediction time: 8.3761 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 4794.23 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 2682.69 KB\n",
      "\n",
      "Results for powerthingnodesorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 2.72s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.8842, MAE = 139691.36, MAPE = 2141.05%\n",
      "q-score: 21.77\n",
      "Prediction time: 7.1926 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.001369\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 4794.23 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 557.07 KB\n",
      "\n",
      "Results for powerthingnodesorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.58s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.7933, MAE = 196257.42, MAPE = 3966.19%\n",
      "q-score: 39.46\n",
      "Prediction time: 4.8373 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for powerthingnodesorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 4794.23 MB\n",
      "\n",
      "Processing dataset: emergencythingwaysorted\n",
      "Universe boundaries for emergencythingwaysorted: (-175.221337, -53.7941359, 179.3313189, 78.22019230000001)\n",
      "Loading data from ../large_files/resultsDistance/emergencythingwaysorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing object coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for emergencythingwaysorted dataset:\n",
      "Max count: 802965.0\n",
      "Min count: 0.0\n",
      "Mean count: 67511.32\n",
      "Median count: 16253.00\n",
      "Total samples: 161514\n",
      "\n",
      "Calculating object features...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 129211\n",
      "\n",
      "Training with sample size: 129211\n",
      "Memory usage: 4795.21 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 94.72s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 62629.46 KB\n",
      "\n",
      "Results for emergencythingwaysorted, Sample Size: 129211\n",
      "Grid Search Time: 94.72s, Training Time: 121.43s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9589, MAE = 7410.52, MAPE = 163.34%\n",
      "q-score: 2.64\n",
      "Prediction time: 27.8663 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000009\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature importance plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 4794.23 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 48674.89 KB\n",
      "\n",
      "Results for emergencythingwaysorted, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 82.35s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9528, MAE = 8077.83, MAPE = 180.95%\n",
      "q-score: 2.80\n",
      "Prediction time: 25.2617 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 4794.24 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 24644.08 KB\n",
      "\n",
      "Results for emergencythingwaysorted, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 37.80s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9350, MAE = 9908.51, MAPE = 230.65%\n",
      "q-score: 3.29\n",
      "Prediction time: 20.3437 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 4794.24 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 5094.60 KB\n",
      "\n",
      "Results for emergencythingwaysorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 6.69s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.8737, MAE = 15386.08, MAPE = 419.83%\n",
      "q-score: 5.05\n",
      "Prediction time: 14.9215 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 4794.24 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 2601.88 KB\n",
      "\n",
      "Results for emergencythingwaysorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 3.40s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.8442, MAE = 18164.52, MAPE = 620.07%\n",
      "q-score: 6.91\n",
      "Prediction time: 14.0168 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 4794.24 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 554.58 KB\n",
      "\n",
      "Results for emergencythingwaysorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.67s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.7631, MAE = 23984.36, MAPE = 937.56%\n",
      "q-score: 9.90\n",
      "Prediction time: 10.9921 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for emergencythingwaysorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 4794.24 MB\n",
      "\n",
      "Processing dataset: historicthingwaysorted\n",
      "Universe boundaries for historicthingwaysorted: (-179.99526020000002, -85.0036942, 179.99597930000002, 78.06750650000001)\n",
      "Loading data from ../large_files/resultsDistance/historicthingwaysorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing object coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for historicthingwaysorted dataset:\n",
      "Max count: 1790224.0\n",
      "Min count: 0.0\n",
      "Mean count: 261684.06\n",
      "Median count: 134375.00\n",
      "Total samples: 358439\n",
      "\n",
      "Calculating object features...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 286751\n",
      "\n",
      "Training with sample size: 286751\n",
      "Memory usage: 4796.20 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 230.34s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 143842.40 KB\n",
      "\n",
      "Results for historicthingwaysorted, Sample Size: 286751\n",
      "Grid Search Time: 230.34s, Training Time: 276.51s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9902, MAE = 11654.85, MAPE = 97.98%\n",
      "q-score: 1.99\n",
      "Prediction time: 34.4713 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000795\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature importance plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 4796.22 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 50635.03 KB\n",
      "\n",
      "Results for historicthingwaysorted, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 77.67s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9808, MAE = 16475.81, MAPE = 137.52%\n",
      "q-score: 2.38\n",
      "Prediction time: 20.4699 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 4746.48 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 25505.55 KB\n",
      "\n",
      "Results for historicthingwaysorted, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 34.45s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9702, MAE = 20593.95, MAPE = 201.93%\n",
      "q-score: 3.02\n",
      "Prediction time: 15.3508 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000006\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 4746.48 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 5228.05 KB\n",
      "\n",
      "Results for historicthingwaysorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 6.20s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9395, MAE = 32707.19, MAPE = 420.52%\n",
      "q-score: 5.21\n",
      "Prediction time: 11.8428 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 4746.48 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 2663.26 KB\n",
      "\n",
      "Results for historicthingwaysorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 3.13s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9183, MAE = 39985.01, MAPE = 780.70%\n",
      "q-score: 8.78\n",
      "Prediction time: 10.1094 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 4746.48 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 560.04 KB\n",
      "\n",
      "Results for historicthingwaysorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.62s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.8511, MAE = 60149.54, MAPE = 1206.84%\n",
      "q-score: 12.98\n",
      "Prediction time: 7.6145 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000003\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for historicthingwaysorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 4746.48 MB\n",
      "\n",
      "Processing dataset: aerowaythingwaysorted\n",
      "Universe boundaries for aerowaythingwaysorted: (-179.88131460000002, -79.7773063, 179.426138, 85.05258450000001)\n",
      "Loading data from ../large_files/resultsDistance/aerowaythingwaysorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing object coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for aerowaythingwaysorted dataset:\n",
      "Max count: 1829409.0\n",
      "Min count: 0.0\n",
      "Mean count: 107433.16\n",
      "Median count: 54304.00\n",
      "Total samples: 368365\n",
      "\n",
      "Calculating object features...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 294692\n",
      "\n",
      "Training with sample size: 294692\n",
      "Memory usage: 4748.44 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 248.16s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 147847.79 KB\n",
      "\n",
      "Results for aerowaythingwaysorted, Sample Size: 294692\n",
      "Grid Search Time: 248.16s, Training Time: 285.95s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9866, MAE = 7239.43, MAPE = 46.06%\n",
      "q-score: 1.47\n",
      "Prediction time: 33.8925 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature importance plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 4792.04 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 50609.47 KB\n",
      "\n",
      "Results for aerowaythingwaysorted, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 73.79s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9740, MAE = 9997.23, MAPE = 67.61%\n",
      "q-score: 1.68\n",
      "Prediction time: 20.4784 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.002757\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 4792.04 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 25476.52 KB\n",
      "\n",
      "Results for aerowaythingwaysorted, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 39.26s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9620, MAE = 12273.15, MAPE = 101.81%\n",
      "q-score: 2.01\n",
      "Prediction time: 15.3859 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.001789\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 4792.04 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 5205.76 KB\n",
      "\n",
      "Results for aerowaythingwaysorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 5.83s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9156, MAE = 19366.33, MAPE = 292.81%\n",
      "q-score: 3.88\n",
      "Prediction time: 11.2547 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 4792.04 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 2641.78 KB\n",
      "\n",
      "Results for aerowaythingwaysorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 2.76s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.8790, MAE = 23340.21, MAPE = 401.43%\n",
      "q-score: 4.94\n",
      "Prediction time: 9.8261 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 4792.04 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 550.57 KB\n",
      "\n",
      "Results for aerowaythingwaysorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.63s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.7820, MAE = 34120.02, MAPE = 760.06%\n",
      "q-score: 8.47\n",
      "Prediction time: 7.4163 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results for aerowaythingwaysorted...\n",
      "Memory usage: 4792.04 MB\n",
      "\n",
      "Processing dataset: arealm\n",
      "Universe boundaries for arealm: (-179.147236, -14.548699, 179.77847, 71.359879)\n",
      "Loading data from ../large_files/resultsDistance/arealm_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing object coordinates...\n",
      "\n",
      "Basic statistics for arealm dataset:\n",
      "Max count: 128233.0\n",
      "Min count: 0.0\n",
      "Mean count: 23800.58\n",
      "Median count: 15460.00\n",
      "Total samples: 25833\n",
      "\n",
      "Calculating object features...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 20666\n",
      "\n",
      "Training with sample size: 20666\n",
      "Memory usage: 4792.04 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 832.74s\n",
      "Best parameters: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 76542.31 KB\n",
      "\n",
      "Results for arealm, Sample Size: 20666\n",
      "Grid Search Time: 832.74s, Training Time: 72.60s\n",
      "Random Forest Parameters: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9807, MAE = 1763.98, MAPE = 129.49%\n",
      "q-score: 2.25\n",
      "Prediction time: 170.3357 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature importance plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 4828.73 MB\n",
      "Using best parameters from max scale: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 37329.63 KB\n",
      "\n",
      "Results for arealm, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 34.75s\n",
      "Random Forest Parameters: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9656, MAE = 2255.06, MAPE = 188.95%\n",
      "q-score: 2.78\n",
      "Prediction time: 147.3723 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 4828.73 MB\n",
      "Using best parameters from max scale: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 18829.85 KB\n",
      "\n",
      "Results for arealm, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 17.90s\n",
      "Random Forest Parameters: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9562, MAE = 2719.76, MAPE = 354.32%\n",
      "q-score: 4.37\n",
      "Prediction time: 131.3817 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 4828.73 MB\n",
      "Using best parameters from max scale: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 3932.16 KB\n",
      "\n",
      "Results for arealm, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 3.07s\n",
      "Random Forest Parameters: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9161, MAE = 4171.37, MAPE = 1098.04%\n",
      "q-score: 11.68\n",
      "Prediction time: 94.4986 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.025876\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for arealm...\n",
      "Saving combined results...\n",
      "All processing completed and results saved.\n",
      "Memory usage: 4828.73 MB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from time import process_time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import psutil\n",
    "import os\n",
    "import re\n",
    "import multiprocessing\n",
    "import joblib\n",
    "import gc\n",
    "from tqdm.notebook import tqdm  # Progress bars for Jupyter\n",
    "\n",
    "# Configuration options\n",
    "VISUALIZE_OBJECTS = False  # Set to True if you want to visualize objects\n",
    "SAVE_INTERMEDIATE_MODELS = True  # Set to False to save only final models\n",
    "\n",
    "# Flag to control whether to use multiple scales or only the maximum scale\n",
    "use_multiple_scales = True  # Set to False to use only maximum scale, True for all scales\n",
    "\n",
    "# Get available CPU cores and set appropriate parallelism\n",
    "n_cores = multiprocessing.cpu_count()\n",
    "n_jobs = max(1, n_cores - 1)  # Leave one core free for system processes\n",
    "print(f\"Using {n_jobs} of {n_cores} available CPU cores\")\n",
    "\n",
    "def monitor_memory():\n",
    "    \"\"\"Print current memory usage of the process\"\"\"\n",
    "    process = psutil.Process()\n",
    "    memory_mb = process.memory_info().rss / (1024 * 1024)\n",
    "    print(f\"Memory usage: {memory_mb:.2f} MB\")\n",
    "\n",
    "def MAPE(actual_values, predicted_values):\n",
    "    \"\"\"Calculate Mean Absolute Percentage Error with special handling for zeros\"\"\"\n",
    "    # Vectorized implementation\n",
    "    actual_flat = actual_values.flatten()\n",
    "    pred_flat = predicted_values.flatten()\n",
    "    \n",
    "    # Create mask for non-zero actual values\n",
    "    non_zero_mask = actual_flat != 0\n",
    "    zero_mask = ~non_zero_mask\n",
    "    \n",
    "    # Calculate MAPE for non-zero elements\n",
    "    mape_sum = 0\n",
    "    count = len(actual_flat)\n",
    "    \n",
    "    if np.any(non_zero_mask):\n",
    "        mape_sum += np.sum(np.abs((actual_flat[non_zero_mask] - pred_flat[non_zero_mask]) / actual_flat[non_zero_mask]))\n",
    "    \n",
    "    if np.any(zero_mask):\n",
    "        mape_sum += np.sum(np.abs(actual_flat[zero_mask] - pred_flat[zero_mask]) / 100)\n",
    "    \n",
    "    return mape_sum / count\n",
    "\n",
    "# Load spatial statistics to get universe boundaries for each dataset\n",
    "print(\"Loading spatial statistics...\")\n",
    "spatial_stats = pd.read_csv('../spatial_statistics.csv')\n",
    "\n",
    "# Directory containing the datasets\n",
    "data_dir = '../large_files/resultsDistance/'  # Changed to distance folder\n",
    "\n",
    "# Parse bounding box information\n",
    "def parse_bbox(bbox_str):\n",
    "    # Extract coordinates from BOX string using regex\n",
    "    pattern = r\"BOX\\(([-\\d\\.]+) ([-\\d\\.]+),([-\\d\\.]+) ([-\\d\\.]+)\\)\"\n",
    "    match = re.search(pattern, bbox_str)\n",
    "    if match:\n",
    "        xmin = float(match.group(1))\n",
    "        ymin = float(match.group(2))\n",
    "        xmax = float(match.group(3))\n",
    "        ymax = float(match.group(4))\n",
    "        return xmin, ymin, xmax, ymax\n",
    "    return -180, -90, 180, 90  # Default if parsing fails\n",
    "\n",
    "# Parse object MBR from format like \"(x1, y1, x2, y2)\"\n",
    "def parse_mbr(mbr_str):\n",
    "    coords = mbr_str.strip('\"()').split(', ')\n",
    "    return [float(coord) for coord in coords]\n",
    "\n",
    "# Extract universe boundaries for each dataset\n",
    "universe_boundaries = {}\n",
    "for _, row in spatial_stats.iterrows():\n",
    "    table_name = row['Table Name']\n",
    "    bbox = parse_bbox(row['Universe Limits (Bounding Box)'])\n",
    "    universe_boundaries[table_name] = bbox\n",
    "\n",
    "# Get list of all CSV files in the directory\n",
    "print(\"Finding dataset files...\")\n",
    "csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "print(f\"Found {len(csv_files)} datasets to process\")\n",
    "\n",
    "# Define the scales of learning\n",
    "scales = [1000, 5000, 10000, 50000, 100000, 500000, 1000000]\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs('../large_files/LearnedModels/distance/RF', exist_ok=True)\n",
    "os.makedirs('../large_files/LearnedModels/distance/RF/visualizations', exist_ok=True)\n",
    "os.makedirs('../large_files/LearnedModels/distance/RF/results', exist_ok=True)\n",
    "\n",
    "# Lists to store all results\n",
    "all_results_list = []\n",
    "\n",
    "# Process each dataset\n",
    "for csv_file in tqdm(csv_files, desc=\"Processing datasets\"):\n",
    "    # Force garbage collection at the start of each dataset\n",
    "    gc.collect()\n",
    "    monitor_memory()\n",
    "    \n",
    "    # Extract dataset name (remove \"_results.csv\")\n",
    "    dataset_name = csv_file.replace('_results.csv', '')\n",
    "    \n",
    "    print(f\"\\nProcessing dataset: {dataset_name}\")\n",
    "    \n",
    "    # Get universe boundaries for this dataset\n",
    "    if dataset_name in universe_boundaries:\n",
    "        univ_xmin, univ_ymin, univ_xmax, univ_ymax = universe_boundaries[dataset_name]\n",
    "    else:\n",
    "        # Default values if dataset not found in spatial stats\n",
    "        univ_xmin, univ_ymin, univ_xmax, univ_ymax = -180, -90, 180, 90\n",
    "    \n",
    "    Surface_univ = (univ_xmax - univ_xmin) * (univ_ymax - univ_ymin)\n",
    "    print(f\"Universe boundaries for {dataset_name}: ({univ_xmin}, {univ_ymin}, {univ_xmax}, {univ_ymax})\")\n",
    "    \n",
    "    # Load dataset - loading required columns for distance dataset\n",
    "    data_path = os.path.join(data_dir, csv_file)\n",
    "    print(f\"Loading data from {data_path}\")\n",
    "    data = pd.read_csv(data_path, usecols=['Object MBR', 'Distance Min', 'Distance Max', 'Count MBR'])\n",
    "    \n",
    "    # Extract object information - ONLY using MBR data\n",
    "    print(\"Parsing object coordinates...\")\n",
    "    Objects_MBR = np.array([parse_mbr(mbr) for mbr in data['Object MBR']])\n",
    "    \n",
    "    # Extract distance information\n",
    "    Distance_Min = data['Distance Min'].values.reshape(-1, 1)\n",
    "    Distance_Max = data['Distance Max'].values.reshape(-1, 1)\n",
    "    \n",
    "    # Target variable: Count MBR\n",
    "    Y = data[['Count MBR']].values\n",
    "    \n",
    "    # Free up memory\n",
    "    del data\n",
    "    gc.collect()\n",
    "    \n",
    "    # Calculate basic statistics\n",
    "    max_count = float(np.max(Y))\n",
    "    min_count = float(np.min(Y))\n",
    "    mean_count = float(np.mean(Y))\n",
    "    median_count = float(np.median(Y))\n",
    "    total_samples = len(Y)\n",
    "\n",
    "    # Display basic statistics for the dataset\n",
    "    print(f\"\\nBasic statistics for {dataset_name} dataset:\")\n",
    "    print(f\"Max count: {max_count}\")\n",
    "    print(f\"Min count: {min_count}\")\n",
    "    print(f\"Mean count: {mean_count:.2f}\")\n",
    "    print(f\"Median count: {median_count:.2f}\")\n",
    "    print(f\"Total samples: {total_samples}\\n\")\n",
    "\n",
    "    # Prepare features using Object MBR instead of True Shape\n",
    "    print(\"Calculating object features...\")\n",
    "\n",
    "    # Extract MBR coordinates\n",
    "    x1 = Objects_MBR[:, 0].reshape(-1, 1)  # Left\n",
    "    y1 = Objects_MBR[:, 1].reshape(-1, 1)  # Bottom\n",
    "    x2 = Objects_MBR[:, 2].reshape(-1, 1)  # Right\n",
    "    y2 = Objects_MBR[:, 3].reshape(-1, 1)  # Top\n",
    "\n",
    "    # Calculate MBR center points\n",
    "    obj_x = (x1 + x2) / 2  # Center X\n",
    "    obj_y = (y1 + y2) / 2  # Center Y\n",
    "\n",
    "    # Calculate MBR dimensions\n",
    "    mbr_width = (x2 - x1)\n",
    "    mbr_height = (y2 - y1)\n",
    "    mbr_area = mbr_width * mbr_height\n",
    "\n",
    "    # Normalized coordinates of MBR center (0-1 range within universe)\n",
    "    norm_x = (obj_x - univ_xmin) / (univ_xmax - univ_xmin) if (univ_xmax - univ_xmin) != 0 else 0.5\n",
    "    norm_y = (obj_y - univ_ymin) / (univ_ymax - univ_ymin) if (univ_ymax - univ_ymin) != 0 else 0.5\n",
    "\n",
    "    # Distance range\n",
    "    distance_range = Distance_Max - Distance_Min\n",
    "\n",
    "    # Distance ratio (max/min)\n",
    "    # Avoid division by zero\n",
    "    min_non_zero = np.where(Distance_Min == 0, 0.0001, Distance_Min)\n",
    "    distance_ratio = Distance_Max / min_non_zero\n",
    "    \n",
    "    # Combine all features\n",
    "    X = np.hstack((\n",
    "        obj_x,           # X coordinate of MBR center\n",
    "        obj_y,           # Y coordinate of MBR center\n",
    "        mbr_width,       # Width of MBR\n",
    "        mbr_height,      # Height of MBR\n",
    "        mbr_area,        # Area of MBR\n",
    "        norm_x,          # Normalized X position (0-1)\n",
    "        norm_y,          # Normalized Y position (0-1)\n",
    "        Distance_Min,    # Minimum distance\n",
    "        Distance_Max,    # Maximum distance\n",
    "        distance_range,  # Range of distance\n",
    "        distance_ratio.reshape(-1, 1)  # Ratio of max/min distance\n",
    "    ))\n",
    "    \n",
    "    # Split the data into 80% train and 20% test\n",
    "    print(\"Splitting data into train and test sets...\")\n",
    "    X_train, X_test_all, y_train, y_test_all = train_test_split(X, Y, test_size=0.2, random_state=3)\n",
    "    \n",
    "    # Visualize the first 100 objects using MBRs\n",
    "    if VISUALIZE_OBJECTS:\n",
    "        print(\"Visualizing objects sample...\")\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        # Only visualize a sample to save time\n",
    "        sample_size = min(100, len(Objects_MBR))\n",
    "        \n",
    "        # Plot universe boundaries\n",
    "        plt.plot([univ_xmin, univ_xmax, univ_xmax, univ_xmin, univ_xmin], \n",
    "                 [univ_ymin, univ_ymin, univ_ymax, univ_ymax, univ_ymin], \n",
    "                 'k-', linewidth=1, alpha=0.5)\n",
    "        \n",
    "        # Plot MBRs\n",
    "        for i in range(sample_size):\n",
    "            x1, y1, x2, y2 = Objects_MBR[i]\n",
    "            rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, \n",
    "                                    linewidth=1, edgecolor='b', facecolor='none', \n",
    "                                    alpha=min(1.0, 0.3 + float(Distance_Min[i])/20))\n",
    "            plt.gca().add_patch(rect)\n",
    "            \n",
    "        plt.colorbar(plt.cm.ScalarMappable(cmap='viridis'), label='Minimum Distance')\n",
    "        plt.xlim(univ_xmin-20, univ_xmax+20)\n",
    "        plt.ylim(univ_ymin-10, univ_ymax+10)\n",
    "        plt.title(f\"Sample MBRs from {dataset_name}\")\n",
    "        plt.savefig(f\"../large_files/LearnedModels/distance/RF/visualizations/{dataset_name}_objects_mbr.png\", dpi=150)\n",
    "        plt.close()\n",
    "    \n",
    "    # Adjust scales to the dataset size\n",
    "    max_size = len(X_train)\n",
    "    print(f\"Training set size: {max_size}\")\n",
    "\n",
    "    if use_multiple_scales:\n",
    "        # Use multiple scales as before\n",
    "        adjusted_scales = [s for s in scales if s <= max_size]\n",
    "        \n",
    "        # Add intermediate 1 million increments for large datasets\n",
    "        if max_size > 1000000:\n",
    "            million_increments = list(range(2000000, max_size, 1000000))\n",
    "            adjusted_scales.extend(million_increments)\n",
    "            \n",
    "        # Add the actual max size if it's not already in the list\n",
    "        if max_size not in adjusted_scales:\n",
    "            adjusted_scales.append(max_size)\n",
    "            \n",
    "        # Sort the scales to ensure they're in ascending order\n",
    "        adjusted_scales.sort()\n",
    "    else:\n",
    "        # Use only the maximum scale\n",
    "        adjusted_scales = [max_size]\n",
    "\n",
    "    # List to store dataset-specific results\n",
    "    dataset_results_list = []\n",
    "\n",
    "    # Store best parameters from max scale training to reuse\n",
    "    best_params = None\n",
    "    \n",
    "    # Process scales in reversed order (largest first)\n",
    "    for sample_size in reversed(adjusted_scales):\n",
    "        print(f\"\\nTraining with sample size: {sample_size}\")\n",
    "        monitor_memory()\n",
    "        \n",
    "        # Create training subset\n",
    "        X_train_sample = X_train[:sample_size, :]\n",
    "        y_train_sample = y_train[:sample_size]\n",
    "        \n",
    "        # Random Forest Regressor parameters - optimized for performance\n",
    "        params_rf = {\n",
    "            \"n_estimators\": [50, 100, 200],\n",
    "            \"max_depth\": [10, 20, 30, None],\n",
    "            \"min_samples_split\": [2, 5, 10]\n",
    "        }\n",
    "        \n",
    "        # For very large datasets, use smaller parameter grid\n",
    "        if sample_size > 100000:\n",
    "            params_rf = {\n",
    "                \"n_estimators\": [50],\n",
    "                \"max_depth\": [None],\n",
    "                \"min_samples_split\": [5]\n",
    "            }\n",
    "            \n",
    "        # Only do GridSearch for the max scale\n",
    "        if sample_size == max_size or best_params is None:\n",
    "            print(\"Performing grid search for optimal parameters...\")\n",
    "            # Use a smaller max_features value to reduce memory usage\n",
    "            rf = RandomForestRegressor(random_state=3, max_features='sqrt', n_jobs=n_jobs)\n",
    "            rf_cv = GridSearchCV(rf, params_rf, cv=3, n_jobs=1, verbose=1)  # Use n_jobs=1 here as RF already uses parallelism\n",
    "            \n",
    "            # Time the grid search\n",
    "            t1_start = process_time()\n",
    "            rf_cv.fit(X_train_sample, y_train_sample.ravel())  # Use ravel for 1D array\n",
    "            t1_stop = process_time()\n",
    "            grid_search_time = t1_stop - t1_start\n",
    "            \n",
    "            # Store best parameters for reuse\n",
    "            best_params = rf_cv.best_params_\n",
    "            print(f\"Grid search complete in {grid_search_time:.2f}s\")\n",
    "            print(f\"Best parameters: {best_params}\")\n",
    "        else:\n",
    "            # Skip grid search for smaller scales, use params from max scale\n",
    "            rf_cv = None\n",
    "            grid_search_time = 0\n",
    "            print(f\"Using best parameters from max scale: {best_params}\")\n",
    "        \n",
    "        # Train the model with best parameters\n",
    "        print(\"Training random forest model...\")\n",
    "        rf = RandomForestRegressor(random_state=3, **best_params, n_jobs=n_jobs)\n",
    "        t2_start = process_time()\n",
    "        rf.fit(X_train_sample, y_train_sample.ravel())  # Use ravel for 1D array\n",
    "        t2_stop = process_time()\n",
    "        training_time = t2_stop - t2_start\n",
    "        \n",
    "        # Make predictions\n",
    "        print(\"Making predictions...\")\n",
    "        y_pred = rf.predict(X_test_all).reshape(-1, 1)  # Reshape to match y_test_all format\n",
    "        \n",
    "        # Calculate metrics\n",
    "        r2_score = rf.score(X_test_all, y_test_all.ravel())\n",
    "        mae_value = MAE(y_test_all, y_pred)\n",
    "        mape_value = MAPE(y_test_all, y_pred)\n",
    "        \n",
    "        # Calculate q-score - vectorized version\n",
    "        print(\"Calculating performance metrics...\")\n",
    "        \n",
    "        # Vectorized q-score calculation\n",
    "        y_true_flat = y_test_all.flatten()\n",
    "        y_pred_flat = y_pred.flatten() if y_pred.ndim > 1 else y_pred\n",
    "        \n",
    "        # Find indices where both values are non-zero\n",
    "        valid_indices = (y_true_flat != 0) & (y_pred_flat != 0)\n",
    "        \n",
    "        if np.any(valid_indices):\n",
    "            ratios = np.maximum(\n",
    "                y_pred_flat[valid_indices] / y_true_flat[valid_indices],\n",
    "                y_true_flat[valid_indices] / y_pred_flat[valid_indices]\n",
    "            )\n",
    "            q_score_mean = np.mean(ratios)\n",
    "        else:\n",
    "            q_score_mean = 0\n",
    "        \n",
    "        # Time prediction performance (10 iterations)\n",
    "        print(\"Measuring prediction performance...\")\n",
    "        total_duration = 0\n",
    "        total_read = 0\n",
    "        total_write = 0\n",
    "        \n",
    "        for _ in range(10):\n",
    "            io_before = psutil.disk_io_counters()\n",
    "            t3_start = process_time()\n",
    "            preds = rf.predict(X_test_all)\n",
    "            preds = np.maximum(0, preds)  # Include this operation in timing\n",
    "            t3_stop = process_time()\n",
    "            io_after = psutil.disk_io_counters()\n",
    "            \n",
    "            total_duration += (t3_stop - t3_start)\n",
    "            total_read += io_after.read_count - io_before.read_count\n",
    "            total_write += io_after.write_count - io_before.write_count\n",
    "        \n",
    "        avg_pred_time_microsec = (total_duration / 10) / len(y_pred) * 1000000\n",
    "        avg_reads = total_read / 10 / len(y_pred)\n",
    "        avg_writes = total_write / 10 / len(y_pred)\n",
    "        \n",
    "        # Save the model using joblib instead of pickle for better efficiency\n",
    "        if SAVE_INTERMEDIATE_MODELS or sample_size == max_size:\n",
    "            print(\"Saving model...\")\n",
    "            filename = f'../large_files/LearnedModels/distance/RF/{dataset_name}_rf_{sample_size}_{training_time:.2f}s_{mape_value:.2%}_{mae_value:.2f}.joblib'\n",
    "            joblib.dump(rf, filename, compress=3)\n",
    "            # Get model file size in KB\n",
    "            model_size_kb = os.path.getsize(filename) / 1024\n",
    "            print(f\"Model size: {model_size_kb:.2f} KB\")\n",
    "        else:\n",
    "            model_size_kb = 0  # Set to 0 if model wasn't saved\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\nResults for {dataset_name}, Sample Size: {sample_size}\")\n",
    "        print(f\"Grid Search Time: {grid_search_time:.2f}s, Training Time: {training_time:.2f}s\")\n",
    "        print(f\"Random Forest Parameters: {best_params}\")\n",
    "        print(f\"Performance: R² = {r2_score:.4f}, MAE = {mae_value:.2f}, MAPE = {mape_value:.2%}\")\n",
    "        print(f\"q-score: {q_score_mean:.2f}\")\n",
    "        print(f\"Prediction time: {avg_pred_time_microsec:.4f} μs/sample\")\n",
    "        print(f\"I/O: Reads={avg_reads:.6f}, Writes={avg_writes:.6f}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Plot actual vs predicted only for the maximum scale\n",
    "        if sample_size == adjusted_scales[-1]:  # Check if this is the maximum scale\n",
    "            print(\"Generating prediction scatter plot...\")\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.scatter(y_test_all, y_pred, s=0.5, alpha=0.5)\n",
    "            plt.xlabel('True Values')\n",
    "            plt.ylabel('Predictions')\n",
    "            plt.title(f\"{dataset_name} - Sample Size: {sample_size} (Maximum)\")\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add diagonal line for perfect predictions\n",
    "            max_val = max(np.max(y_test_all), np.max(y_pred))\n",
    "            plt.plot([0, max_val], [0, max_val], 'r--', alpha=0.5)\n",
    "            \n",
    "            plt.savefig(f\"../large_files/LearnedModels/distance/RF/visualizations/{dataset_name}_{sample_size}_prediction.png\", dpi=150)\n",
    "            plt.close()  # Close to free memory\n",
    "            \n",
    "            # Feature importance plot\n",
    "            if hasattr(rf, 'feature_importances_'):\n",
    "                print(\"Generating feature importance plot...\")\n",
    "                plt.figure(figsize=(12, 6))\n",
    "                feature_names = [\n",
    "                    'Center X', 'Center Y', 'Width', 'Height', 'Area',\n",
    "                    'Norm X', 'Norm Y', 'Min Dist', 'Max Dist', \n",
    "                    'Dist Range', 'Dist Ratio'\n",
    "                ]\n",
    "                importances = rf.feature_importances_\n",
    "                indices = np.argsort(importances)[::-1]\n",
    "                \n",
    "                plt.bar(range(X.shape[1]), importances[indices])\n",
    "                plt.xticks(range(X.shape[1]), [feature_names[i] for i in indices], rotation=45)\n",
    "                plt.title(f'Feature Importances for {dataset_name}')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"../large_files/LearnedModels/distance/RF/visualizations/{dataset_name}_feature_importance.png\", dpi=150)\n",
    "                plt.close()\n",
    "            \n",
    "            # Create a scatter plot comparing predicted vs real values for first 100 objects\n",
    "            print(\"Generating side-by-side comparison plot...\")\n",
    "            \n",
    "            # Get predictions for first 100 test samples\n",
    "            sample_indices = range(min(100, len(X_test_all)))\n",
    "            X_sample = X_test_all[sample_indices]\n",
    "            y_sample_true = y_test_all[sample_indices].flatten()\n",
    "            y_sample_pred = rf.predict(X_sample)\n",
    "            # Ensure non-negative predictions\n",
    "            y_sample_pred = np.maximum(0, y_sample_pred)\n",
    "            \n",
    "            plt.figure(figsize=(20, 10))\n",
    "            plt.scatter(range(len(sample_indices)), y_sample_pred, c='blue', \n",
    "                        label='Predicted number of objects (Random Forest)', alpha=0.7, s=100)\n",
    "            plt.scatter(range(len(sample_indices)), y_sample_true, c='green', \n",
    "                        label='Real number of objects', alpha=0.7, s=100)\n",
    "            \n",
    "            plt.title(f'{dataset_name} - First {len(sample_indices)} Objects: Predicted vs Real Values', fontsize=16)\n",
    "            plt.xlabel('Object Index', fontsize=14)\n",
    "            plt.ylabel('Number of objects within distance', fontsize=14)\n",
    "            plt.legend(fontsize=12)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save the plot\n",
    "            plt.savefig(f\"../large_files/LearnedModels/distance/RF/visualizations/{dataset_name}_comparison_plot.png\", dpi=150)\n",
    "            plt.close()\n",
    "        \n",
    "        # Store results in list (more efficient than DataFrame concat)\n",
    "        result_row = {\n",
    "            'Dataset': dataset_name,\n",
    "            'Sample_Size': sample_size,\n",
    "            'Training_Time': training_time,\n",
    "            'Best_Params': str(best_params),\n",
    "            'R2_Score': r2_score,\n",
    "            'MAE': mae_value,\n",
    "            'MAPE': float(mape_value),\n",
    "            'Q_Score': q_score_mean,\n",
    "            'Pred_Time_Microseconds': avg_pred_time_microsec,\n",
    "            'IO_Reads': avg_reads,\n",
    "            'IO_Writes': avg_writes,\n",
    "            'Model_Size_KB': model_size_kb,\n",
    "            'Max_Count': max_count,\n",
    "            'Min_Count': min_count,\n",
    "            'Mean_Count': mean_count,\n",
    "            'Median_Count': median_count,\n",
    "            'Total_Samples': total_samples\n",
    "        }\n",
    "        \n",
    "        dataset_results_list.append(result_row)\n",
    "        all_results_list.append(result_row)\n",
    "        \n",
    "        # Clean up to free memory\n",
    "        if sample_size != max_size:  # Don't delete for max size as we might need it\n",
    "            del X_train_sample, y_train_sample, rf\n",
    "            gc.collect()\n",
    "    \n",
    "    # Save results for this dataset\n",
    "    print(f\"Saving results for {dataset_name}...\")\n",
    "    dataset_results = pd.DataFrame(dataset_results_list)\n",
    "    dataset_results.to_csv(f'../large_files/LearnedModels/distance/RF/results/{dataset_name}_results.csv', index=False)\n",
    "    \n",
    "    # Clear memory before next dataset\n",
    "    del X_train, X_test_all, y_train, y_test_all, Objects_MBR, Distance_Min, Distance_Max\n",
    "    gc.collect()\n",
    "    \n",
    "# Save all results\n",
    "print(\"Saving combined results...\")\n",
    "all_results = pd.DataFrame(all_results_list)\n",
    "all_results.to_csv('../large_files/LearnedModels/distance/RF/all_results.csv', index=False)\n",
    "\n",
    "print(\"All processing completed and results saved.\")\n",
    "monitor_memory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4963.792079,
   "end_time": "2025-04-19T09:40:04.351859",
   "environment_variables": {},
   "exception": null,
   "input_path": "/home/adminlias/nadir/Spatial-Selectivity-Ext/distance_filter/randomForestRegressor.ipynb",
   "output_path": "/home/adminlias/nadir/Spatial-Selectivity-Ext/distance_filter/output_randomForestRegressor.ipynb",
   "parameters": {},
   "start_time": "2025-04-19T08:17:20.559780",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "04491415faec48f3a613e6f89663ee56": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "097c333f3d524539955154093b7749d8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "125bea93c4e64ab7a0c4b4d20637ec3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6f628754709b41cba60f0f841ca9c3a3",
        "IPY_MODEL_9758c42bc34a4f398e0e3888b00ff35e",
        "IPY_MODEL_ea555fa6d3d040a0a6d13d97866d345c"
       ],
       "layout": "IPY_MODEL_04491415faec48f3a613e6f89663ee56"
      }
     },
     "184863078c7842ee8e7cd2ab62c9dade": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "53955db88b1344a086b575dceeaf33d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "56aa37715e374b8991d7ddf6e3247fb7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "644be2a32e19418398279ffbc9765b00": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6f628754709b41cba60f0f841ca9c3a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9e32719e6f90433ab02ccb7a4151ce18",
       "placeholder": "​",
       "style": "IPY_MODEL_56aa37715e374b8991d7ddf6e3247fb7",
       "value": "Processing datasets: 100%"
      }
     },
     "9758c42bc34a4f398e0e3888b00ff35e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_097c333f3d524539955154093b7749d8",
       "max": 14.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_644be2a32e19418398279ffbc9765b00",
       "value": 14.0
      }
     },
     "9e32719e6f90433ab02ccb7a4151ce18": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ea555fa6d3d040a0a6d13d97866d345c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_53955db88b1344a086b575dceeaf33d1",
       "placeholder": "​",
       "style": "IPY_MODEL_184863078c7842ee8e7cd2ab62c9dade",
       "value": " 14/14 [1:22:40&lt;00:00, 143.73s/it]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}