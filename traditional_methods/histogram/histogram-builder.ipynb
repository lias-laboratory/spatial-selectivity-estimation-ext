{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded metadata for 14 datasets\n",
      "Found 14 datasets to process\n",
      "\n",
      "Processing dataset: yago2\n",
      "Building histogram for yago2 with batch processing...\n",
      "Creating 512x512 grid (262144 cells)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing grid cells: 100%|██████████| 262144/262144 [1:22:50<00:00, 52.74it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram built successfully for yago2\n",
      "\n",
      "Processing dataset: craftwaysorted\n",
      "Building histogram for craftwaysorted with batch processing...\n",
      "Creating 104x104 grid (10816 cells)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing grid cells: 100%|██████████| 10816/10816 [00:00<00:00, 21252.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram built successfully for craftwaysorted\n",
      "\n",
      "Processing dataset: zcta5\n",
      "Building histogram for zcta5 with batch processing...\n",
      "Creating 57x57 grid (3249 cells)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing grid cells: 100%|██████████| 3249/3249 [00:00<00:00, 19863.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram built successfully for zcta5\n",
      "\n",
      "Processing dataset: areawater\n",
      "Building histogram for areawater with batch processing...\n",
      "Creating 478x478 grid (228484 cells)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing grid cells: 100%|██████████| 228484/228484 [00:13<00:00, 17369.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram built successfully for areawater\n",
      "\n",
      "Processing dataset: aerowaythingnodesorted\n",
      "Building histogram for aerowaythingnodesorted with batch processing...\n",
      "Creating 89x89 grid (7921 cells)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing grid cells: 100%|██████████| 7921/7921 [00:00<00:00, 21664.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram built successfully for aerowaythingnodesorted\n",
      "\n",
      "Processing dataset: emergencythingwaysorted\n",
      "Building histogram for emergencythingwaysorted with batch processing...\n",
      "Creating 284x284 grid (80656 cells)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing grid cells: 100%|██████████| 80656/80656 [00:03<00:00, 23602.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram built successfully for emergencythingwaysorted\n",
      "\n",
      "Processing dataset: historicthingwaysorted\n",
      "Building histogram for historicthingwaysorted with batch processing...\n",
      "Creating 423x423 grid (178929 cells)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing grid cells: 100%|██████████| 178929/178929 [00:08<00:00, 21017.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram built successfully for historicthingwaysorted\n",
      "\n",
      "Processing dataset: aerowaythingwaysorted\n",
      "Building histogram for aerowaythingwaysorted with batch processing...\n",
      "Creating 429x429 grid (184041 cells)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing grid cells: 100%|██████████| 184041/184041 [00:10<00:00, 17323.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram built successfully for aerowaythingwaysorted\n",
      "\n",
      "Processing dataset: cyclewaythingwaysorted\n",
      "Building histogram for cyclewaythingwaysorted with batch processing...\n",
      "Creating 512x512 grid (262144 cells)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing grid cells: 100%|██████████| 262144/262144 [00:19<00:00, 13660.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram built successfully for cyclewaythingwaysorted\n",
      "\n",
      "Processing dataset: powerthingwaysorted\n",
      "Building histogram for powerthingwaysorted with batch processing...\n",
      "Creating 512x512 grid (262144 cells)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing grid cells: 100%|██████████| 262144/262144 [01:11<00:00, 3649.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram built successfully for powerthingwaysorted\n",
      "\n",
      "Processing dataset: leisurewaysorted\n",
      "Building histogram for leisurewaysorted with batch processing...\n",
      "Creating 512x512 grid (262144 cells)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing grid cells: 100%|██████████| 262144/262144 [01:36<00:00, 2721.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram built successfully for leisurewaysorted\n",
      "\n",
      "Processing dataset: barrierthingwaysorted\n",
      "Building histogram for barrierthingwaysorted with batch processing...\n",
      "Creating 512x512 grid (262144 cells)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing grid cells: 100%|██████████| 262144/262144 [01:29<00:00, 2920.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram built successfully for barrierthingwaysorted\n",
      "\n",
      "Processing dataset: powerthingnodesorted\n",
      "Building histogram for powerthingnodesorted with batch processing...\n",
      "Creating 512x512 grid (262144 cells)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing grid cells: 100%|██████████| 262144/262144 [01:07<00:00, 3910.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram built successfully for powerthingnodesorted\n",
      "\n",
      "Processing dataset: arealm\n",
      "Building histogram for arealm with batch processing...\n",
      "Creating 113x113 grid (12769 cells)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing grid cells: 100%|██████████| 12769/12769 [00:00<00:00, 21789.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram built successfully for arealm\n",
      "All histograms built successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import psycopg2\n",
    "import re\n",
    "import configparser\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "\n",
    "class SpatialHistogramBuilder:\n",
    "    def __init__(self, grid_resolution_factor=0.1, data_dir=\"../../large_files\"):\n",
    "        \"\"\"\n",
    "        Initialize the histogram-based spatial estimator\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        grid_resolution_factor : float\n",
    "            The factor to determine grid resolution (0.1 = ~10% of data objects)\n",
    "        data_dir : str\n",
    "            Directory containing results files\n",
    "        \"\"\"\n",
    "        self.grid_resolution_factor = grid_resolution_factor\n",
    "        self.data_dir = data_dir\n",
    "        self.universe_boundaries = {}\n",
    "        self.dataset_sizes = {}\n",
    "        \n",
    "        # Create directories for saving histograms and results\n",
    "        os.makedirs(\"../../large_files/traditional_methods/histogram\", exist_ok=True)\n",
    "        os.makedirs(\"../../large_files/traditional_methods/histogram/results\", exist_ok=True)\n",
    "        os.makedirs(\"../../large_files/traditional_methods/histogram/visualizations\", exist_ok=True)\n",
    "        \n",
    "        # Load dataset metadata from spatial_statistics.csv\n",
    "        self.load_spatial_statistics()\n",
    "        \n",
    "    def load_spatial_statistics(self):\n",
    "        \"\"\"Load dataset information from spatial_statistics.csv\"\"\"\n",
    "        try:\n",
    "            stats_df = pd.read_csv(\"../../spatial_statistics.csv\")\n",
    "            for _, row in stats_df.iterrows():\n",
    "                table_name = row['Table Name']\n",
    "                total_objects = row['Total Spatial Objects']\n",
    "                bbox_str = row['Universe Limits (Bounding Box)']\n",
    "                \n",
    "                # Parse bounding box\n",
    "                bbox = self.parse_bbox(bbox_str)\n",
    "                self.universe_boundaries[table_name] = bbox\n",
    "                self.dataset_sizes[table_name] = int(total_objects)\n",
    "                \n",
    "            print(f\"Loaded metadata for {len(self.universe_boundaries)} datasets\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading spatial statistics: {e}\")\n",
    "    \n",
    "    def parse_bbox(self, bbox_str):\n",
    "        \"\"\"Parse bounding box string into coordinates\"\"\"\n",
    "        pattern = r\"BOX\\(([-\\d\\.]+) ([-\\d\\.]+),([-\\d\\.]+) ([-\\d\\.]+)\\)\"\n",
    "        match = re.search(pattern, bbox_str)\n",
    "        if match:\n",
    "            xmin = float(match.group(1))\n",
    "            ymin = float(match.group(2))\n",
    "            xmax = float(match.group(3))\n",
    "            ymax = float(match.group(4))\n",
    "            return (xmin, ymin, xmax, ymax)\n",
    "        return (-180, -90, 180, 90)  # Default if parsing fails\n",
    "    \n",
    "    def connect_to_database(self):\n",
    "        \"\"\"Connect to the database containing spatial data\"\"\"\n",
    "        # Load config from config.ini\n",
    "        config = configparser.ConfigParser()\n",
    "        config.read(\"../../dataset_generation/config.ini\")\n",
    "        db_params = config[\"database\"]\n",
    "        \n",
    "        try:\n",
    "            conn = psycopg2.connect(\n",
    "                dbname=db_params[\"dbname\"],\n",
    "                user=db_params[\"user\"],\n",
    "                password=db_params[\"password\"],\n",
    "                host=db_params[\"host\"],\n",
    "                port=db_params[\"port\"]\n",
    "            )\n",
    "            return conn\n",
    "        except psycopg2.Error as e:\n",
    "            print(f\"Database connection error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def build_histogram(self, dataset_name, save=True, batch_size=100):\n",
    "        \"\"\"\n",
    "        Build a 2D histogram for the specified dataset\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        dataset_name : str\n",
    "            Name of the dataset to build histogram for\n",
    "        save : bool\n",
    "            Whether to save the histogram to a file\n",
    "        batch_size : int\n",
    "            Number of cells to process in each SQL query batch for optimization\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        np.ndarray\n",
    "            2D histogram grid\n",
    "        \"\"\"\n",
    "        print(f\"Building histogram for {dataset_name}...\")\n",
    "        \n",
    "        # Get universe boundaries and total objects\n",
    "        if dataset_name not in self.universe_boundaries:\n",
    "            raise ValueError(f\"Unknown dataset: {dataset_name}\")\n",
    "            \n",
    "        univ_xmin, univ_ymin, univ_xmax, univ_ymax = self.universe_boundaries[dataset_name]\n",
    "        total_objects = self.dataset_sizes[dataset_name]\n",
    "        \n",
    "        # Determine grid resolution - sqrt to get cells in each dimension\n",
    "        num_grids = int(total_objects * self.grid_resolution_factor)\n",
    "        # The min between nm_grids and 512 x 512 is to prevent too large grids\n",
    "        num_grids = min(num_grids, 512 * 512)\n",
    "        num_grids_sqrt = int(np.sqrt(num_grids))\n",
    "        \n",
    "        print(f\"Creating {num_grids_sqrt}x{num_grids_sqrt} grid ({num_grids_sqrt*num_grids_sqrt} cells)\")\n",
    "        \n",
    "        # Initialize grid\n",
    "        grid = np.zeros((num_grids_sqrt, num_grids_sqrt), dtype=int)\n",
    "        \n",
    "        try:\n",
    "            # Connect to database\n",
    "            conn = self.connect_to_database()\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # Calculate cell dimensions\n",
    "            cell_width = (univ_xmax - univ_xmin) / num_grids_sqrt\n",
    "            cell_height = (univ_ymax - univ_ymin) / num_grids_sqrt\n",
    "            \n",
    "            # Process each grid cell with progress tracking\n",
    "            with tqdm(total=num_grids_sqrt * num_grids_sqrt, desc=\"Processing grid cells\") as pbar:\n",
    "                # Process grid cells row by row, column by column\n",
    "                for i in range(num_grids_sqrt):\n",
    "                    for j in range(num_grids_sqrt):\n",
    "                        # Calculate cell boundaries\n",
    "                        cell_min_x = univ_xmin + i * cell_width\n",
    "                        cell_min_y = univ_ymin + j * cell_height\n",
    "                        cell_max_x = cell_min_x + cell_width\n",
    "                        cell_max_y = cell_min_y + cell_height\n",
    "                        \n",
    "                        # Query to count objects that intersect with this cell\n",
    "                        cursor.execute(f\"\"\"\n",
    "                            SELECT COUNT(*) \n",
    "                            FROM {dataset_name}_mbr \n",
    "                            WHERE geometry && ST_MakeEnvelope(%s, %s, %s, %s, 4326)\n",
    "                        \"\"\", (cell_min_x, cell_min_y, cell_max_x, cell_max_y))\n",
    "                        \n",
    "                        # Get the count and store in grid\n",
    "                        count = cursor.fetchone()[0]\n",
    "                        grid[i, j] = count\n",
    "                        \n",
    "                        # Update progress bar\n",
    "                        pbar.update(1)\n",
    "            \n",
    "            conn.close()\n",
    "            \n",
    "            # Save the grid to a file\n",
    "            if save:\n",
    "                np.save(f\"../../large_files/traditional_methods/histogram/{dataset_name}_histogram.npy\", grid)\n",
    "                # Also save the metadata\n",
    "                metadata = {\n",
    "                    'dimensions': (num_grids_sqrt, num_grids_sqrt),\n",
    "                    'universe': (univ_xmin, univ_ymin, univ_xmax, univ_ymax),\n",
    "                    'objects': total_objects\n",
    "                }\n",
    "                np.save(f\"../../large_files/traditional_methods/histogram/{dataset_name}_metadata.npy\", metadata)\n",
    "                \n",
    "                # Generate a visualization\n",
    "                self.visualize_histogram(dataset_name, grid, \n",
    "                                        (univ_xmin, univ_ymin, univ_xmax, univ_ymax),\n",
    "                                        save=True)\n",
    "            \n",
    "            print(f\"Histogram built successfully for {dataset_name}\")\n",
    "            return grid\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error building histogram for {dataset_name}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def visualize_histogram(self, dataset_name, grid, universe, save=False):\n",
    "        \"\"\"Generate a visualization of the histogram\"\"\"\n",
    "        univ_xmin, univ_ymin, univ_xmax, univ_ymax = universe\n",
    "        \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.imshow(grid.T, cmap='viridis', origin='lower',\n",
    "                  extent=[univ_xmin, univ_xmax, univ_ymin, univ_ymax],\n",
    "                  aspect='auto', interpolation='nearest')\n",
    "        plt.colorbar(label='Objects per cell')\n",
    "        plt.title(f'Histogram for {dataset_name} - {grid.shape[0]}x{grid.shape[1]} grid')\n",
    "        plt.xlabel('Longitude')\n",
    "        plt.ylabel('Latitude')\n",
    "        \n",
    "        if save:\n",
    "            plt.savefig(f\"../../large_files/traditional_methods/histogram/visualizations/{dataset_name}_histogram.png\", dpi=150)\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "    def build_histogram_batch(self, dataset_name, save=True, batch_size=500):\n",
    "        \"\"\"\n",
    "        Build a 2D histogram using batch processing for better efficiency\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        dataset_name : str\n",
    "            Name of the dataset to build histogram for\n",
    "        save : bool\n",
    "            Whether to save the histogram to a file\n",
    "        batch_size : int\n",
    "            Number of cells to process in each batch\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        np.ndarray\n",
    "            2D histogram grid\n",
    "        \"\"\"\n",
    "        print(f\"Building histogram for {dataset_name} with batch processing...\")\n",
    "        \n",
    "        # Get universe boundaries and total objects\n",
    "        if dataset_name not in self.universe_boundaries:\n",
    "            raise ValueError(f\"Unknown dataset: {dataset_name}\")\n",
    "            \n",
    "        univ_xmin, univ_ymin, univ_xmax, univ_ymax = self.universe_boundaries[dataset_name]\n",
    "        total_objects = self.dataset_sizes[dataset_name]\n",
    "        \n",
    "        # Determine grid resolution - sqrt to get cells in each dimension\n",
    "        num_grids = int(total_objects * self.grid_resolution_factor)\n",
    "        num_grids = min(num_grids, 512 * 512)\n",
    "        num_grids_sqrt = int(np.sqrt(num_grids))\n",
    "        \n",
    "        print(f\"Creating {num_grids_sqrt}x{num_grids_sqrt} grid ({num_grids_sqrt*num_grids_sqrt} cells)\")\n",
    "        \n",
    "        # Initialize grid\n",
    "        grid = np.zeros((num_grids_sqrt, num_grids_sqrt), dtype=int)\n",
    "        \n",
    "        try:\n",
    "            # Connect to database\n",
    "            conn = self.connect_to_database()\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # Calculate cell dimensions\n",
    "            cell_width = (univ_xmax - univ_xmin) / num_grids_sqrt\n",
    "            cell_height = (univ_ymax - univ_ymin) / num_grids_sqrt\n",
    "            \n",
    "            # Create temporary table with non-conflicting column names\n",
    "            cursor.execute(\"\"\"\n",
    "                DROP TABLE IF EXISTS temp_grid_cells;\n",
    "                CREATE TEMP TABLE temp_grid_cells (\n",
    "                    row_idx INT, \n",
    "                    col_idx INT, \n",
    "                    min_x FLOAT, \n",
    "                    min_y FLOAT,\n",
    "                    max_x FLOAT,\n",
    "                    max_y FLOAT\n",
    "                );\n",
    "            \"\"\")\n",
    "            \n",
    "            # Process in batches\n",
    "            total_cells = num_grids_sqrt * num_grids_sqrt\n",
    "            batch_count = (total_cells + batch_size - 1) // batch_size\n",
    "            \n",
    "            with tqdm(total=total_cells, desc=\"Processing grid cells\") as pbar:\n",
    "                for batch in range(batch_count):\n",
    "                    start_idx = batch * batch_size\n",
    "                    end_idx = min((batch + 1) * batch_size, total_cells)\n",
    "                    \n",
    "                    # Clear temp table\n",
    "                    cursor.execute(\"TRUNCATE temp_grid_cells\")\n",
    "                    \n",
    "                    # Insert batch of cells into temp table\n",
    "                    batch_cells = []\n",
    "                    for idx in range(start_idx, end_idx):\n",
    "                        i = idx // num_grids_sqrt\n",
    "                        j = idx % num_grids_sqrt\n",
    "                        \n",
    "                        cell_min_x = univ_xmin + i * cell_width\n",
    "                        cell_min_y = univ_ymin + j * cell_height\n",
    "                        cell_max_x = cell_min_x + cell_width\n",
    "                        cell_max_y = cell_min_y + cell_height\n",
    "                        \n",
    "                        batch_cells.append((i, j, cell_min_x, cell_min_y, cell_max_x, cell_max_y))\n",
    "                    \n",
    "                    # Insert batch into temp table\n",
    "                    args_str = ','.join(cursor.mogrify(\"(%s,%s,%s,%s,%s,%s)\", cell).decode('utf-8') \n",
    "                                     for cell in batch_cells)\n",
    "                    if args_str:\n",
    "                        cursor.execute(f\"INSERT INTO temp_grid_cells VALUES {args_str}\")\n",
    "                        \n",
    "                        # Query to count objects that intersect with each cell in this batch\n",
    "                        cursor.execute(f\"\"\"\n",
    "                            SELECT row_idx, col_idx, COUNT(geometry) \n",
    "                            FROM temp_grid_cells c\n",
    "                            LEFT JOIN {dataset_name}_mbr m\n",
    "                              ON m.geometry && ST_MakeEnvelope(c.min_x, c.min_y, c.max_x, c.max_y, 4326)\n",
    "                            GROUP BY c.row_idx, c.col_idx\n",
    "                        \"\"\")\n",
    "                        \n",
    "                        # Process results\n",
    "                        for row_idx, col_idx, count in cursor.fetchall():\n",
    "                            grid[row_idx, col_idx] = count\n",
    "                            \n",
    "                        # Update progress\n",
    "                        pbar.update(end_idx - start_idx)\n",
    "            \n",
    "            conn.close()\n",
    "            \n",
    "            # Save the grid to a file\n",
    "            if save:\n",
    "                np.save(f\"../../large_files/traditional_methods/histogram/{dataset_name}_histogram.npy\", grid)\n",
    "                metadata = {\n",
    "                    'dimensions': (num_grids_sqrt, num_grids_sqrt),\n",
    "                    'universe': (univ_xmin, univ_ymin, univ_xmax, univ_ymax),\n",
    "                    'objects': total_objects,\n",
    "                    'grid_resolution_factor': self.grid_resolution_factor,\n",
    "                    'model_size_bytes': grid.nbytes,\n",
    "                    'num_cells': num_grids_sqrt * num_grids_sqrt\n",
    "                }\n",
    "                np.save(f\"../../large_files/traditional_methods/histogram/{dataset_name}_metadata.npy\", metadata)\n",
    "                \n",
    "                # Generate a visualization\n",
    "                self.visualize_histogram(dataset_name, grid, \n",
    "                                       (univ_xmin, univ_ymin, univ_xmax, univ_ymax),\n",
    "                                       save=True)\n",
    "            \n",
    "            print(f\"Histogram built successfully for {dataset_name}\")\n",
    "            return grid\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error building histogram for {dataset_name}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "\n",
    "# Main execution function\n",
    "def build_all_histograms(resolution_factor=0.1):\n",
    "    \"\"\"\n",
    "    Build histograms for all datasets in the spatial_statistics.csv file\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    resolution_factor : float\n",
    "        The factor to determine grid resolution (0.1 = ~10% of data objects)\n",
    "    \"\"\"\n",
    "    # Create histogram builder\n",
    "    builder = SpatialHistogramBuilder(grid_resolution_factor=resolution_factor)\n",
    "    \n",
    "    # Get all dataset names\n",
    "    dataset_names = list(builder.universe_boundaries.keys())\n",
    "    \n",
    "    print(f\"Found {len(dataset_names)} datasets to process\")\n",
    "    \n",
    "    # Build histograms for each dataset\n",
    "    for dataset_name in dataset_names:\n",
    "        try:\n",
    "            print(f\"\\nProcessing dataset: {dataset_name}\")\n",
    "            # Use the batch version which avoids column name conflicts\n",
    "            builder.build_histogram_batch(dataset_name, save=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {dataset_name}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Build histograms for all datasets with default resolution factor\n",
    "    build_all_histograms(resolution_factor=0.1)\n",
    "    print(\"All histograms built successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
