{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "442b4d59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T04:56:04.546368Z",
     "iopub.status.busy": "2025-03-12T04:56:04.545661Z",
     "iopub.status.idle": "2025-03-12T05:43:12.070736Z",
     "shell.execute_reply": "2025-03-12T05:43:12.069293Z"
    },
    "papermill": {
     "duration": 2827.534548,
     "end_time": "2025-03-12T05:43:12.073078",
     "exception": false,
     "start_time": "2025-03-12T04:56:04.538530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 29 of 30 available CPU cores\n",
      "Loading spatial statistics...\n",
      "Finding dataset files...\n",
      "Found 14 datasets to process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c02271e5bdf4cc0be0976a7b35e1a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing datasets:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 202.30 MB\n",
      "\n",
      "Processing dataset: historicthingwaysorted\n",
      "Universe boundaries for historicthingwaysorted: (-179.99526020000002, -85.0036942, 179.99597930000002, 78.06750650000001)\n",
      "Loading data from ../large_files/resultsIntersects/historicthingwaysorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing MBR coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for historicthingwaysorted dataset:\n",
      "Max count: 1792176.0\n",
      "Min count: 0.0\n",
      "Mean count: 29765.11\n",
      "Median count: 16.00\n",
      "Total samples: 358439\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 286751\n",
      "\n",
      "Training with sample size: 286751\n",
      "Memory usage: 247.50 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 200.49s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 67233.50 KB\n",
      "\n",
      "Results for historicthingwaysorted, Sample Size: 286751\n",
      "Grid Search Time: 200.49s, Training Time: 124.15s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9992, MAE = 827.39, MAPE = 36.88%\n",
      "q-score: 1.66\n",
      "Prediction time: 18.4893 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 1223.60 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 25621.84 KB\n",
      "\n",
      "Results for historicthingwaysorted, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 36.33s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9983, MAE = 1257.90, MAPE = 77.76%\n",
      "q-score: 2.35\n",
      "Prediction time: 13.6373 μs/sample\n",
      "I/O: Reads=0.000001, Writes=0.000003\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 770.95 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 13559.34 KB\n",
      "\n",
      "Results for historicthingwaysorted, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 16.12s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9973, MAE = 1677.22, MAPE = 135.06%\n",
      "q-score: 3.27\n",
      "Prediction time: 12.1604 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 771.15 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 3101.70 KB\n",
      "\n",
      "Results for historicthingwaysorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 3.15s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9903, MAE = 3849.15, MAPE = 710.12%\n",
      "q-score: 11.60\n",
      "Prediction time: 9.7329 μs/sample\n",
      "I/O: Reads=0.000001, Writes=0.000010\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 771.15 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 1687.14 KB\n",
      "\n",
      "Results for historicthingwaysorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 1.73s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9789, MAE = 5924.95, MAPE = 1278.51%\n",
      "q-score: 19.79\n",
      "Prediction time: 8.8817 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 771.15 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 379.43 KB\n",
      "\n",
      "Results for historicthingwaysorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.47s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.7788, MAE = 21030.48, MAPE = 10093.99%\n",
      "q-score: 145.76\n",
      "Prediction time: 7.4072 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for historicthingwaysorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 762.40 MB\n",
      "\n",
      "Processing dataset: powerthingnodesorted\n",
      "Universe boundaries for powerthingnodesorted: (-177.92741900000001, -77.8453164, 178.47197400000002, 78.2256315)\n",
      "Loading data from ../large_files/resultsIntersects/powerthingnodesorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing MBR coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for powerthingnodesorted dataset:\n",
      "Max count: 10512575.0\n",
      "Min count: 0.0\n",
      "Mean count: 174964.97\n",
      "Median count: 41.00\n",
      "Total samples: 2102514\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1682011\n",
      "\n",
      "Training with sample size: 1682011\n",
      "Memory usage: 977.60 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 1767.36s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 412494.78 KB\n",
      "\n",
      "Results for powerthingnodesorted, Sample Size: 1682011\n",
      "Grid Search Time: 1767.36s, Training Time: 1083.75s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9996, MAE = 3626.45, MAPE = 70.87%\n",
      "q-score: 2.24\n",
      "Prediction time: 29.6385 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000000\n",
      "Memory usage: 5471.32 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 250520.33 KB\n",
      "\n",
      "Results for powerthingnodesorted, Sample Size: 1000000\n",
      "Grid Search Time: 0.00s, Training Time: 608.56s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9994, MAE = 4414.30, MAPE = 109.22%\n",
      "q-score: 2.88\n",
      "Prediction time: 25.6077 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 500000\n",
      "Memory usage: 2317.92 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 129276.92 KB\n",
      "\n",
      "Results for powerthingnodesorted, Sample Size: 500000\n",
      "Grid Search Time: 0.00s, Training Time: 262.25s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9992, MAE = 5434.37, MAPE = 212.09%\n",
      "q-score: 4.65\n",
      "Prediction time: 20.2088 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 2735.47 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 28145.17 KB\n",
      "\n",
      "Results for powerthingnodesorted, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 34.94s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9967, MAE = 11023.86, MAPE = 1212.69%\n",
      "q-score: 21.36\n",
      "Prediction time: 10.5321 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000004\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 2765.18 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 14712.89 KB\n",
      "\n",
      "Results for powerthingnodesorted, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 18.92s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9943, MAE = 15208.25, MAPE = 2663.58%\n",
      "q-score: 45.40\n",
      "Prediction time: 8.8200 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 2765.59 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 3353.24 KB\n",
      "\n",
      "Results for powerthingnodesorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 3.08s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9745, MAE = 36093.96, MAPE = 21541.38%\n",
      "q-score: 352.73\n",
      "Prediction time: 6.8112 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 2765.59 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 1776.25 KB\n",
      "\n",
      "Results for powerthingnodesorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 1.66s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9364, MAE = 56514.19, MAPE = 41941.10%\n",
      "q-score: 684.94\n",
      "Prediction time: 6.0264 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 2765.60 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 409.63 KB\n",
      "\n",
      "Results for powerthingnodesorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.48s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.6780, MAE = 117322.96, MAPE = 135309.22%\n",
      "q-score: 2211.44\n",
      "Prediction time: 4.6104 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for powerthingnodesorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 2714.27 MB\n",
      "\n",
      "Processing dataset: cyclewaythingwaysorted\n",
      "Universe boundaries for cyclewaythingwaysorted: (-175.2093065, -75.1027861, 176.92582230000002, 71.0488105)\n",
      "Loading data from ../large_files/resultsIntersects/cyclewaythingwaysorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing MBR coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for cyclewaythingwaysorted dataset:\n",
      "Max count: 5334900.0\n",
      "Min count: 0.0\n",
      "Mean count: 76783.36\n",
      "Median count: 0.00\n",
      "Total samples: 1067063\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 853650\n",
      "\n",
      "Training with sample size: 853650\n",
      "Memory usage: 2652.12 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 745.64s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 157680.92 KB\n",
      "\n",
      "Results for cyclewaythingwaysorted, Sample Size: 853650\n",
      "Grid Search Time: 745.64s, Training Time: 470.00s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9994, MAE = 1630.39, MAPE = 35.26%\n",
      "q-score: 1.68\n",
      "Prediction time: 21.1123 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 500000\n",
      "Memory usage: 3275.54 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 97287.61 KB\n",
      "\n",
      "Results for cyclewaythingwaysorted, Sample Size: 500000\n",
      "Grid Search Time: 0.00s, Training Time: 252.17s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9992, MAE = 2047.18, MAPE = 51.13%\n",
      "q-score: 1.96\n",
      "Prediction time: 16.8494 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 2805.72 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 22707.16 KB\n",
      "\n",
      "Results for cyclewaythingwaysorted, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 37.06s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9971, MAE = 4211.56, MAPE = 177.27%\n",
      "q-score: 4.06\n",
      "Prediction time: 10.1389 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000002\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 2813.52 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 12158.66 KB\n",
      "\n",
      "Results for cyclewaythingwaysorted, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 18.24s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9947, MAE = 5932.51, MAPE = 319.85%\n",
      "q-score: 6.12\n",
      "Prediction time: 8.9583 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 2813.57 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 2902.30 KB\n",
      "\n",
      "Results for cyclewaythingwaysorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 3.15s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9793, MAE = 13916.00, MAPE = 1910.25%\n",
      "q-score: 27.69\n",
      "Prediction time: 7.2423 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000075\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 2813.57 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 1573.39 KB\n",
      "\n",
      "Results for cyclewaythingwaysorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 1.75s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9464, MAE = 22779.78, MAPE = 4833.90%\n",
      "q-score: 68.76\n",
      "Prediction time: 6.3894 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 2813.57 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 361.05 KB\n",
      "\n",
      "Results for cyclewaythingwaysorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.45s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.7422, MAE = 54332.14, MAPE = 14383.56%\n",
      "q-score: 183.28\n",
      "Prediction time: 4.8276 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for cyclewaythingwaysorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 2813.57 MB\n",
      "\n",
      "Processing dataset: aerowaythingwaysorted\n",
      "Universe boundaries for aerowaythingwaysorted: (-179.88131460000002, -79.7773063, 179.426138, 85.05258450000001)\n",
      "Loading data from ../large_files/resultsIntersects/aerowaythingwaysorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing MBR coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for aerowaythingwaysorted dataset:\n",
      "Max count: 1841551.0\n",
      "Min count: 0.0\n",
      "Mean count: 32185.32\n",
      "Median count: 227.00\n",
      "Total samples: 368365\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 294692\n",
      "\n",
      "Training with sample size: 294692\n",
      "Memory usage: 2815.55 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 201.61s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 85873.54 KB\n",
      "\n",
      "Results for aerowaythingwaysorted, Sample Size: 294692\n",
      "Grid Search Time: 201.61s, Training Time: 125.42s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9988, MAE = 1260.26, MAPE = 78.47%\n",
      "q-score: 2.17\n",
      "Prediction time: 21.1853 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 2847.97 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 31119.99 KB\n",
      "\n",
      "Results for aerowaythingwaysorted, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 36.99s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9973, MAE = 2023.40, MAPE = 153.26%\n",
      "q-score: 3.20\n",
      "Prediction time: 15.0556 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 2847.97 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 16213.42 KB\n",
      "\n",
      "Results for aerowaythingwaysorted, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 16.98s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9953, MAE = 2768.56, MAPE = 268.04%\n",
      "q-score: 4.74\n",
      "Prediction time: 13.1175 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 2847.97 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 3677.18 KB\n",
      "\n",
      "Results for aerowaythingwaysorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 3.04s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9800, MAE = 6227.93, MAPE = 1029.77%\n",
      "q-score: 14.01\n",
      "Prediction time: 10.1246 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000062\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 2847.97 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 1969.31 KB\n",
      "\n",
      "Results for aerowaythingwaysorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 1.57s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9502, MAE = 9564.00, MAPE = 1836.95%\n",
      "q-score: 24.08\n",
      "Prediction time: 9.4653 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000011\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 2847.97 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 444.05 KB\n",
      "\n",
      "Results for aerowaythingwaysorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.39s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.8047, MAE = 19564.15, MAPE = 5101.08%\n",
      "q-score: 60.97\n",
      "Prediction time: 7.3817 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for aerowaythingwaysorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 2847.97 MB\n",
      "\n",
      "Processing dataset: zcta5\n",
      "Universe boundaries for zcta5: (-176.684744, -14.373776, 145.830505, 71.341324)\n",
      "Loading data from ../large_files/resultsIntersects/zcta5_results.csv\n",
      "Parsing MBR coordinates...\n",
      "\n",
      "Basic statistics for zcta5 dataset:\n",
      "Max count: 33136.0\n",
      "Min count: 0.0\n",
      "Mean count: 676.56\n",
      "Median count: 0.00\n",
      "Total samples: 6626\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 5300\n",
      "\n",
      "Training with sample size: 5300\n",
      "Memory usage: 2847.97 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 168.05s\n",
      "Best parameters: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 770.95 KB\n",
      "\n",
      "Results for zcta5, Sample Size: 5300\n",
      "Grid Search Time: 168.05s, Training Time: 1.22s\n",
      "Random Forest Parameters: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Performance: R² = 0.9855, MAE = 98.29, MAPE = 112.59%\n",
      "q-score: 9.10\n",
      "Prediction time: 56.3718 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 2847.96 MB\n",
      "Using best parameters from max scale: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 725.92 KB\n",
      "\n",
      "Results for zcta5, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 1.16s\n",
      "Random Forest Parameters: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Performance: R² = 0.9826, MAE = 108.54, MAPE = 153.92%\n",
      "q-score: 12.02\n",
      "Prediction time: 56.1309 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 2847.97 MB\n",
      "Using best parameters from max scale: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 184.12 KB\n",
      "\n",
      "Results for zcta5, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.35s\n",
      "Random Forest Parameters: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Performance: R² = 0.8722, MAE = 300.90, MAPE = 279.52%\n",
      "q-score: 18.37\n",
      "Prediction time: 49.6397 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for zcta5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 2847.96 MB\n",
      "\n",
      "Processing dataset: leisurewaysorted\n",
      "Universe boundaries for leisurewaysorted: (-179.8728244, -89.6957847, 179.8091866, 81.0280175)\n",
      "Loading data from ../large_files/resultsIntersects/leisurewaysorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing MBR coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for leisurewaysorted dataset:\n",
      "Max count: 29382688.0\n",
      "Min count: 0.0\n",
      "Mean count: 489269.22\n",
      "Median count: 253.00\n",
      "Total samples: 5000000\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 4000000\n",
      "\n",
      "Training with sample size: 4000000\n",
      "Memory usage: 2850.97 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 5023.35s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 981739.18 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 4000000\n",
      "Grid Search Time: 5023.35s, Training Time: 3002.09s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9998, MAE = 5874.89, MAPE = 36.51%\n",
      "q-score: 1.59\n",
      "Prediction time: 36.4353 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000002\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 3000000\n",
      "Memory usage: 12158.12 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 745362.14 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 3000000\n",
      "Grid Search Time: 0.00s, Training Time: 2074.49s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9998, MAE = 6547.71, MAPE = 44.10%\n",
      "q-score: 1.72\n",
      "Prediction time: 33.9996 μs/sample\n",
      "I/O: Reads=0.000006, Writes=0.000002\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 2000000\n",
      "Memory usage: 4353.87 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 505715.64 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 2000000\n",
      "Grid Search Time: 0.00s, Training Time: 1405.79s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9998, MAE = 7440.47, MAPE = 57.63%\n",
      "q-score: 1.92\n",
      "Prediction time: 30.9645 μs/sample\n",
      "I/O: Reads=0.000006, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000000\n",
      "Memory usage: 4047.94 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 260879.05 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 1000000\n",
      "Grid Search Time: 0.00s, Training Time: 587.72s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9996, MAE = 9643.63, MAPE = 88.89%\n",
      "q-score: 2.39\n",
      "Prediction time: 26.2512 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 500000\n",
      "Memory usage: 4368.09 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 134877.54 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 500000\n",
      "Grid Search Time: 0.00s, Training Time: 249.28s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9993, MAE = 12755.09, MAPE = 150.07%\n",
      "q-score: 4.23\n",
      "Prediction time: 20.4930 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000383\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 4374.20 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 29445.59 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 37.12s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9979, MAE = 24762.55, MAPE = 581.66%\n",
      "q-score: 9.47\n",
      "Prediction time: 10.4511 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 4374.20 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 15403.85 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 18.22s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9965, MAE = 34017.94, MAPE = 1215.96%\n",
      "q-score: 17.84\n",
      "Prediction time: 8.6862 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 4374.20 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 3479.10 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 3.13s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9848, MAE = 77765.15, MAPE = 8226.19%\n",
      "q-score: 100.86\n",
      "Prediction time: 6.5046 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000250\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 4374.20 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 1864.96 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 1.53s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9672, MAE = 115805.67, MAPE = 17847.51%\n",
      "q-score: 206.54\n",
      "Prediction time: 5.6281 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000170\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 4374.20 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 429.61 KB\n",
      "\n",
      "Results for leisurewaysorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.45s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.7109, MAE = 373390.79, MAPE = 124069.78%\n",
      "q-score: 1442.90\n",
      "Prediction time: 4.1071 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for leisurewaysorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 4374.20 MB\n",
      "\n",
      "Processing dataset: areawater\n",
      "Universe boundaries for areawater: (-179.231086, -14.601813, 179.859681, 71.441059)\n",
      "Loading data from ../large_files/resultsIntersects/areawater_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing MBR coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for areawater dataset:\n",
      "Max count: 2292737.0\n",
      "Min count: 0.0\n",
      "Mean count: 43941.55\n",
      "Median count: 0.00\n",
      "Total samples: 458552\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 366841\n",
      "\n",
      "Training with sample size: 366841\n",
      "Memory usage: 4376.20 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 242.19s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 24328.84 KB\n",
      "\n",
      "Results for areawater, Sample Size: 366841\n",
      "Grid Search Time: 242.19s, Training Time: 166.69s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9995, MAE = 839.96, MAPE = 17.91%\n",
      "q-score: 2.22\n",
      "Prediction time: 8.4062 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 4376.20 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 7377.40 KB\n",
      "\n",
      "Results for areawater, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 31.85s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9984, MAE = 1581.00, MAPE = 64.86%\n",
      "q-score: 5.56\n",
      "Prediction time: 6.9202 μs/sample\n",
      "I/O: Reads=0.000048, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 4374.20 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 3917.96 KB\n",
      "\n",
      "Results for areawater, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 13.34s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9972, MAE = 2212.31, MAPE = 148.17%\n",
      "q-score: 9.94\n",
      "Prediction time: 6.3492 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 4374.20 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 968.20 KB\n",
      "\n",
      "Results for areawater, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 2.80s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9882, MAE = 4887.32, MAPE = 660.51%\n",
      "q-score: 37.15\n",
      "Prediction time: 5.7803 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 4374.20 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 552.58 KB\n",
      "\n",
      "Results for areawater, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 1.31s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9765, MAE = 7267.46, MAPE = 1471.06%\n",
      "q-score: 67.36\n",
      "Prediction time: 5.2330 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 4374.20 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 125.65 KB\n",
      "\n",
      "Results for areawater, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.36s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9229, MAE = 16718.65, MAPE = 8105.42%\n",
      "q-score: 365.71\n",
      "Prediction time: 4.6732 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000008\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for areawater...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 4374.20 MB\n",
      "\n",
      "Processing dataset: barrierthingwaysorted\n",
      "Universe boundaries for barrierthingwaysorted: (-179.7595238, -70.776382, 179.19591350000002, 78.2501675)\n",
      "Loading data from ../large_files/resultsIntersects/barrierthingwaysorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing MBR coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for barrierthingwaysorted dataset:\n",
      "Max count: 22908267.0\n",
      "Min count: 0.0\n",
      "Mean count: 399933.77\n",
      "Median count: 329.00\n",
      "Total samples: 4581670\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 3665336\n",
      "\n",
      "Training with sample size: 3665336\n",
      "Memory usage: 4378.20 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 4443.09s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 932302.78 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 3665336\n",
      "Grid Search Time: 4443.09s, Training Time: 2535.52s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9999, MAE = 4564.90, MAPE = 35.92%\n",
      "q-score: 1.56\n",
      "Prediction time: 38.8029 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000002\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 3000000\n",
      "Memory usage: 11808.93 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 770867.50 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 3000000\n",
      "Grid Search Time: 0.00s, Training Time: 2099.67s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9998, MAE = 4924.53, MAPE = 40.84%\n",
      "q-score: 1.64\n",
      "Prediction time: 36.6875 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000003\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 2000000\n",
      "Memory usage: 4838.32 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 524579.47 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 2000000\n",
      "Grid Search Time: 0.00s, Training Time: 1359.75s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9998, MAE = 5721.24, MAPE = 50.66%\n",
      "q-score: 1.79\n",
      "Prediction time: 33.0839 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000002\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000000\n",
      "Memory usage: 4654.96 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 271718.72 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 1000000\n",
      "Grid Search Time: 0.00s, Training Time: 595.93s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9996, MAE = 7535.82, MAPE = 83.67%\n",
      "q-score: 2.28\n",
      "Prediction time: 28.1572 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 500000\n",
      "Memory usage: 4884.76 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 140767.90 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 500000\n",
      "Grid Search Time: 0.00s, Training Time: 251.20s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9994, MAE = 9733.86, MAPE = 124.70%\n",
      "q-score: 2.88\n",
      "Prediction time: 22.1800 μs/sample\n",
      "I/O: Reads=0.000006, Writes=0.000448\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 4890.16 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 30706.31 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 36.34s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9980, MAE = 18846.01, MAPE = 409.93%\n",
      "q-score: 6.69\n",
      "Prediction time: 10.8613 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 4890.16 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 16015.42 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 17.50s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9964, MAE = 26019.60, MAPE = 775.38%\n",
      "q-score: 11.48\n",
      "Prediction time: 9.0484 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 4890.16 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 3589.68 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 3.44s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9841, MAE = 62575.97, MAPE = 4278.59%\n",
      "q-score: 51.57\n",
      "Prediction time: 6.6606 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000300\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 4890.16 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 1916.17 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 1.63s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9689, MAE = 88018.83, MAPE = 9358.92%\n",
      "q-score: 112.40\n",
      "Prediction time: 5.7861 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000170\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 4890.16 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 436.47 KB\n",
      "\n",
      "Results for barrierthingwaysorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.43s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.6708, MAE = 316898.11, MAPE = 83658.35%\n",
      "q-score: 955.84\n",
      "Prediction time: 4.2005 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for barrierthingwaysorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 4890.16 MB\n",
      "\n",
      "Processing dataset: yago2\n",
      "Universe boundaries for yago2: (-179.98473, -90.0, 180.0, 90.0)\n",
      "Loading data from ../large_files/resultsIntersects/yago2_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing MBR coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for yago2 dataset:\n",
      "Max count: 4494691.0\n",
      "Min count: 0.0\n",
      "Mean count: 100894.17\n",
      "Median count: 17450.00\n",
      "Total samples: 898942\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 719153\n",
      "\n",
      "Training with sample size: 719153\n",
      "Memory usage: 4892.13 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 619.83s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 329080.08 KB\n",
      "\n",
      "Results for yago2, Sample Size: 719153\n",
      "Grid Search Time: 619.83s, Training Time: 365.49s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9994, MAE = 2415.38, MAPE = 3.10%\n",
      "q-score: 1.03\n",
      "Prediction time: 40.4835 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000003\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 500000\n",
      "Memory usage: 6292.79 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 229645.12 KB\n",
      "\n",
      "Results for yago2, Sample Size: 500000\n",
      "Grid Search Time: 0.00s, Training Time: 252.24s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9992, MAE = 2799.44, MAPE = 3.73%\n",
      "q-score: 1.04\n",
      "Prediction time: 36.2114 μs/sample\n",
      "I/O: Reads=0.000033, Writes=0.002455\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 4912.00 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 46908.55 KB\n",
      "\n",
      "Results for yago2, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 39.04s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9965, MAE = 5763.27, MAPE = 8.34%\n",
      "q-score: 1.09\n",
      "Prediction time: 17.5928 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 4912.00 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 23672.65 KB\n",
      "\n",
      "Results for yago2, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 17.61s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9945, MAE = 7692.12, MAPE = 12.02%\n",
      "q-score: 1.13\n",
      "Prediction time: 12.7321 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 4912.00 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 4889.23 KB\n",
      "\n",
      "Results for yago2, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 3.15s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9693, MAE = 17883.77, MAPE = 327.89%\n",
      "q-score: 4.22\n",
      "Prediction time: 9.1879 μs/sample\n",
      "I/O: Reads=0.000001, Writes=0.000413\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 4912.00 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 2510.33 KB\n",
      "\n",
      "Results for yago2, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 1.64s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9415, MAE = 24876.62, MAPE = 447.43%\n",
      "q-score: 5.43\n",
      "Prediction time: 8.0740 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 4912.00 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 535.14 KB\n",
      "\n",
      "Results for yago2, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.43s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.8264, MAE = 43649.54, MAPE = 1043.34%\n",
      "q-score: 11.53\n",
      "Prediction time: 5.5916 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for yago2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 4912.00 MB\n",
      "\n",
      "Processing dataset: arealm\n",
      "Universe boundaries for arealm: (-179.147236, -14.548699, 179.77847, 71.359879)\n",
      "Loading data from ../large_files/resultsIntersects/arealm_results.csv\n",
      "Parsing MBR coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for arealm dataset:\n",
      "Max count: 129098.0\n",
      "Min count: 0.0\n",
      "Mean count: 2283.77\n",
      "Median count: 0.00\n",
      "Total samples: 25833\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 20666\n",
      "\n",
      "Training with sample size: 20666\n",
      "Memory usage: 4911.11 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 477.74s\n",
      "Best parameters: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 11331.57 KB\n",
      "\n",
      "Results for arealm, Sample Size: 20666\n",
      "Grid Search Time: 477.74s, Training Time: 17.67s\n",
      "Random Forest Parameters: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9943, MAE = 170.85, MAPE = 61.69%\n",
      "q-score: 4.71\n",
      "Prediction time: 83.2261 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n",
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 4911.11 MB\n",
      "Using best parameters from max scale: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 5896.83 KB\n",
      "\n",
      "Results for arealm, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 7.92s\n",
      "Random Forest Parameters: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9841, MAE = 278.87, MAPE = 82.07%\n",
      "q-score: 5.29\n",
      "Prediction time: 76.5489 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 4911.11 MB\n",
      "Using best parameters from max scale: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 3276.05 KB\n",
      "\n",
      "Results for arealm, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 4.45s\n",
      "Random Forest Parameters: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9765, MAE = 346.38, MAPE = 121.06%\n",
      "q-score: 7.66\n",
      "Prediction time: 72.7006 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000252\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 4911.11 MB\n",
      "Using best parameters from max scale: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 783.34 KB\n",
      "\n",
      "Results for arealm, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 1.64s\n",
      "Random Forest Parameters: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.8223, MAE = 1102.43, MAPE = 1242.85%\n",
      "q-score: 72.07\n",
      "Prediction time: 60.8022 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results for arealm...\n",
      "Memory usage: 4911.11 MB\n",
      "\n",
      "Processing dataset: aerowaythingnodesorted\n",
      "Universe boundaries for aerowaythingnodesorted: (-179.88088960000002, -90.0, 179.951004, 83.08333590000001)\n",
      "Loading data from ../large_files/resultsIntersects/aerowaythingnodesorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing MBR coordinates...\n",
      "\n",
      "Basic statistics for aerowaythingnodesorted dataset:\n",
      "Max count: 79139.0\n",
      "Min count: 0.0\n",
      "Mean count: 1260.61\n",
      "Median count: 7.00\n",
      "Total samples: 15843\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 12674\n",
      "\n",
      "Training with sample size: 12674\n",
      "Memory usage: 4911.00 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 408.62s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 28501.57 KB\n",
      "\n",
      "Results for aerowaythingnodesorted, Sample Size: 12674\n",
      "Grid Search Time: 408.62s, Training Time: 15.50s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9781, MAE = 252.63, MAPE = 462.65%\n",
      "q-score: 8.32\n",
      "Prediction time: 185.8478 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n",
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 4910.99 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 22810.09 KB\n",
      "\n",
      "Results for aerowaythingnodesorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 12.84s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9784, MAE = 271.26, MAPE = 493.46%\n",
      "q-score: 8.79\n",
      "Prediction time: 168.7624 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000316\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 4911.00 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 12036.63 KB\n",
      "\n",
      "Results for aerowaythingnodesorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 6.47s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9613, MAE = 372.63, MAPE = 730.61%\n",
      "q-score: 12.55\n",
      "Prediction time: 153.5441 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 4911.00 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 2764.45 KB\n",
      "\n",
      "Results for aerowaythingnodesorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 2.11s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.8061, MAE = 860.53, MAPE = 3130.52%\n",
      "q-score: 49.29\n",
      "Prediction time: 126.3392 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for aerowaythingnodesorted...\n",
      "Memory usage: 4911.00 MB\n",
      "\n",
      "Processing dataset: powerthingwaysorted\n",
      "Universe boundaries for powerthingwaysorted: (-179.5002188, -75.1012051, 178.4574038, 82.5247908)\n",
      "Loading data from ../large_files/resultsIntersects/powerthingwaysorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing MBR coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for powerthingwaysorted dataset:\n",
      "Max count: 13586343.0\n",
      "Min count: 0.0\n",
      "Mean count: 236405.41\n",
      "Median count: 147.00\n",
      "Total samples: 2717289\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 2173831\n",
      "\n",
      "Training with sample size: 2173831\n",
      "Memory usage: 4914.99 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 2385.50s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 539415.81 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 2173831\n",
      "Grid Search Time: 2385.50s, Training Time: 1465.60s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9997, MAE = 4036.76, MAPE = 42.74%\n",
      "q-score: 1.72\n",
      "Prediction time: 32.3260 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000003\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 2000000\n",
      "Memory usage: 7952.78 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 497694.30 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 2000000\n",
      "Grid Search Time: 0.00s, Training Time: 1276.46s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9997, MAE = 4178.82, MAPE = 46.37%\n",
      "q-score: 1.78\n",
      "Prediction time: 30.4944 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000000\n",
      "Memory usage: 4783.88 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 255406.16 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 1000000\n",
      "Grid Search Time: 0.00s, Training Time: 584.55s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9995, MAE = 5586.65, MAPE = 72.52%\n",
      "q-score: 2.21\n",
      "Prediction time: 26.1944 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000008\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 500000\n",
      "Memory usage: 4873.23 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 131465.05 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 500000\n",
      "Grid Search Time: 0.00s, Training Time: 249.09s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9991, MAE = 7198.89, MAPE = 124.42%\n",
      "q-score: 3.03\n",
      "Prediction time: 20.4749 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 4907.42 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 28654.33 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 38.96s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9975, MAE = 13551.89, MAPE = 501.41%\n",
      "q-score: 8.58\n",
      "Prediction time: 10.5173 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000159\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 4908.11 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 15018.21 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 17.21s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9955, MAE = 18944.15, MAPE = 1109.47%\n",
      "q-score: 16.65\n",
      "Prediction time: 8.9939 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000001\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 4908.11 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 3374.78 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 3.39s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9736, MAE = 46573.98, MAPE = 4971.44%\n",
      "q-score: 67.57\n",
      "Prediction time: 6.8085 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000002\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 4908.11 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 1818.21 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 1.61s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9514, MAE = 67815.11, MAPE = 12630.27%\n",
      "q-score: 162.69\n",
      "Prediction time: 5.9807 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 4908.11 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 422.96 KB\n",
      "\n",
      "Results for powerthingwaysorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.45s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.6974, MAE = 159314.35, MAPE = 45746.97%\n",
      "q-score: 545.04\n",
      "Prediction time: 4.3391 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for powerthingwaysorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 4908.11 MB\n",
      "\n",
      "Processing dataset: emergencythingwaysorted\n",
      "Universe boundaries for emergencythingwaysorted: (-175.221337, -53.7941359, 179.3313189, 78.22019230000001)\n",
      "Loading data from ../large_files/resultsIntersects/emergencythingwaysorted_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing MBR coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for emergencythingwaysorted dataset:\n",
      "Max count: 807533.0\n",
      "Min count: 0.0\n",
      "Mean count: 13253.96\n",
      "Median count: 15.00\n",
      "Total samples: 161514\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 129211\n",
      "\n",
      "Training with sample size: 129211\n",
      "Memory usage: 4910.08 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 79.65s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 32391.67 KB\n",
      "\n",
      "Results for emergencythingwaysorted, Sample Size: 129211\n",
      "Grid Search Time: 79.65s, Training Time: 45.80s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9984, MAE = 467.79, MAPE = 56.74%\n",
      "q-score: 2.00\n",
      "Prediction time: 20.2994 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n",
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 100000\n",
      "Memory usage: 4909.09 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 25611.41 KB\n",
      "\n",
      "Results for emergencythingwaysorted, Sample Size: 100000\n",
      "Grid Search Time: 0.00s, Training Time: 35.57s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9982, MAE = 519.28, MAPE = 66.13%\n",
      "q-score: 2.15\n",
      "Prediction time: 18.4719 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 50000\n",
      "Memory usage: 4909.11 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 13541.54 KB\n",
      "\n",
      "Results for emergencythingwaysorted, Sample Size: 50000\n",
      "Grid Search Time: 0.00s, Training Time: 18.12s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9962, MAE = 779.47, MAPE = 132.02%\n",
      "q-score: 3.21\n",
      "Prediction time: 17.0749 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 4909.11 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 3159.73 KB\n",
      "\n",
      "Results for emergencythingwaysorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 3.30s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9851, MAE = 2061.08, MAPE = 570.67%\n",
      "q-score: 9.55\n",
      "Prediction time: 14.5177 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 4909.11 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 1712.95 KB\n",
      "\n",
      "Results for emergencythingwaysorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 1.74s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.9694, MAE = 3227.60, MAPE = 1173.53%\n",
      "q-score: 18.26\n",
      "Prediction time: 13.5812 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 4909.36 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Training random forest model...\n",
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 390.38 KB\n",
      "\n",
      "Results for emergencythingwaysorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 0.41s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Performance: R² = 0.7169, MAE = 9314.28, MAPE = 3573.76%\n",
      "q-score: 53.40\n",
      "Prediction time: 11.5074 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "Saving results for emergencythingwaysorted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 4909.36 MB\n",
      "\n",
      "Processing dataset: craftwaysorted\n",
      "Universe boundaries for craftwaysorted: (-175.2000514, -65.2458821, 175.3397782, 69.6673353)\n",
      "Loading data from ../large_files/resultsIntersects/craftwaysorted_results.csv\n",
      "Parsing MBR coordinates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for craftwaysorted dataset:\n",
      "Max count: 108929.0\n",
      "Min count: 0.0\n",
      "Mean count: 1705.24\n",
      "Median count: 0.00\n",
      "Total samples: 21822\n",
      "\n",
      "Calculating rectangle densities...\n",
      "Splitting data into train and test sets...\n",
      "Training set size: 17457\n",
      "\n",
      "Training with sample size: 17457\n",
      "Memory usage: 4908.43 MB\n",
      "Performing grid search for optimal parameters...\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete in 503.64s\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 26119.31 KB\n",
      "\n",
      "Results for craftwaysorted, Sample Size: 17457\n",
      "Grid Search Time: 503.64s, Training Time: 20.84s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9931, MAE = 176.71, MAPE = 76.19%\n",
      "q-score: 2.63\n",
      "Prediction time: 145.7200 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000160\n",
      "--------------------------------------------------------------------------------\n",
      "Generating prediction scatter plot...\n",
      "Generating side-by-side comparison plot...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sample size: 10000\n",
      "Memory usage: 4908.43 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 16074.05 KB\n",
      "\n",
      "Results for craftwaysorted, Sample Size: 10000\n",
      "Grid Search Time: 0.00s, Training Time: 12.16s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9885, MAE = 247.02, MAPE = 142.45%\n",
      "q-score: 3.89\n",
      "Prediction time: 129.2658 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 5000\n",
      "Memory usage: 4908.43 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 8795.61 KB\n",
      "\n",
      "Results for craftwaysorted, Sample Size: 5000\n",
      "Grid Search Time: 0.00s, Training Time: 6.02s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.9710, MAE = 406.57, MAPE = 241.02%\n",
      "q-score: 5.68\n",
      "Prediction time: 113.8700 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000115\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training with sample size: 1000\n",
      "Memory usage: 4908.43 MB\n",
      "Using best parameters from max scale: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training random forest model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "Measuring prediction performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model size: 2042.62 KB\n",
      "\n",
      "Results for craftwaysorted, Sample Size: 1000\n",
      "Grid Search Time: 0.00s, Training Time: 1.86s\n",
      "Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Performance: R² = 0.7582, MAE = 1211.56, MAPE = 725.38%\n",
      "q-score: 14.54\n",
      "Prediction time: 96.7891 μs/sample\n",
      "I/O: Reads=0.000000, Writes=0.000069\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results for craftwaysorted...\n",
      "Saving combined results...\n",
      "All processing completed and results saved.\n",
      "Memory usage: 4908.43 MB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from time import process_time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import psutil\n",
    "import os\n",
    "import re\n",
    "import multiprocessing\n",
    "import joblib\n",
    "import gc\n",
    "from tqdm.notebook import tqdm  # Progress bars for Jupyter\n",
    "\n",
    "# Configuration options\n",
    "VISUALIZE_RECTANGLES = False  # Set to True if you want to visualize rectangles\n",
    "SAVE_INTERMEDIATE_MODELS = True  # Set to False to save only final models\n",
    "\n",
    "# Flag to control whether to use multiple scales or only the maximum scale\n",
    "use_multiple_scales = True  # Set to False to use only maximum scale, True for all scales\n",
    "\n",
    "# Get available CPU cores and set appropriate parallelism\n",
    "n_cores = multiprocessing.cpu_count()\n",
    "n_jobs = max(1, n_cores - 1)  # Leave one core free for system processes\n",
    "print(f\"Using {n_jobs} of {n_cores} available CPU cores\")\n",
    "\n",
    "def monitor_memory():\n",
    "    \"\"\"Print current memory usage of the process\"\"\"\n",
    "    process = psutil.Process()\n",
    "    memory_mb = process.memory_info().rss / (1024 * 1024)\n",
    "    print(f\"Memory usage: {memory_mb:.2f} MB\")\n",
    "\n",
    "def MAPE(actual_values, predicted_values):\n",
    "    \"\"\"Calculate Mean Absolute Percentage Error with special handling for zeros\"\"\"\n",
    "    # Vectorized implementation\n",
    "    actual_flat = actual_values.flatten()\n",
    "    pred_flat = predicted_values.flatten()\n",
    "    \n",
    "    # Create mask for non-zero actual values\n",
    "    non_zero_mask = actual_flat != 0\n",
    "    zero_mask = ~non_zero_mask\n",
    "    \n",
    "    # Calculate MAPE for non-zero elements\n",
    "    mape_sum = 0\n",
    "    count = len(actual_flat)\n",
    "    \n",
    "    if np.any(non_zero_mask):\n",
    "        mape_sum += np.sum(np.abs((actual_flat[non_zero_mask] - pred_flat[non_zero_mask]) / actual_flat[non_zero_mask]))\n",
    "    \n",
    "    if np.any(zero_mask):\n",
    "        mape_sum += np.sum(np.abs(actual_flat[zero_mask] - pred_flat[zero_mask]) / 100)\n",
    "    \n",
    "    return mape_sum / count\n",
    "\n",
    "# Load spatial statistics to get universe boundaries for each dataset\n",
    "print(\"Loading spatial statistics...\")\n",
    "spatial_stats = pd.read_csv('../spatial_statistics.csv')\n",
    "\n",
    "# Directory containing the datasets\n",
    "data_dir = '../large_files/resultsIntersects/'\n",
    "\n",
    "# Parse bounding box information\n",
    "def parse_bbox(bbox_str):\n",
    "    # Extract coordinates from BOX string using regex\n",
    "    pattern = r\"BOX\\(([-\\d\\.]+) ([-\\d\\.]+),([-\\d\\.]+) ([-\\d\\.]+)\\)\"\n",
    "    match = re.search(pattern, bbox_str)\n",
    "    if match:\n",
    "        xmin = float(match.group(1))\n",
    "        ymin = float(match.group(2))\n",
    "        xmax = float(match.group(3))\n",
    "        ymax = float(match.group(4))\n",
    "        return xmin, ymin, xmax, ymax\n",
    "    return -180, -90, 180, 90  # Default if parsing fails\n",
    "\n",
    "# Extract universe boundaries for each dataset\n",
    "universe_boundaries = {}\n",
    "for _, row in spatial_stats.iterrows():\n",
    "    table_name = row['Table Name']\n",
    "    bbox = parse_bbox(row['Universe Limits (Bounding Box)'])\n",
    "    universe_boundaries[table_name] = bbox\n",
    "\n",
    "# Get list of all CSV files in the directory\n",
    "print(\"Finding dataset files...\")\n",
    "csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "print(f\"Found {len(csv_files)} datasets to process\")\n",
    "\n",
    "# Define the scales of learning\n",
    "scales = [1000, 5000, 10000, 50000, 100000, 500000, 1000000]\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs('../large_files/LearnedModels/intersect/RF', exist_ok=True)\n",
    "os.makedirs('../large_files/LearnedModels/intersect/RF/visualizations', exist_ok=True)\n",
    "os.makedirs('../large_files/LearnedModels/intersect/RF/results', exist_ok=True)\n",
    "\n",
    "# Lists to store all results\n",
    "all_results_list = []\n",
    "\n",
    "# Process each dataset\n",
    "for csv_file in tqdm(csv_files, desc=\"Processing datasets\"):\n",
    "    # Force garbage collection at the start of each dataset\n",
    "    gc.collect()\n",
    "    monitor_memory()\n",
    "    \n",
    "    # Extract dataset name (remove \"_results.csv\")\n",
    "    dataset_name = csv_file.replace('_results.csv', '')\n",
    "    \n",
    "    print(f\"\\nProcessing dataset: {dataset_name}\")\n",
    "    \n",
    "    # Get universe boundaries for this dataset\n",
    "    if dataset_name in universe_boundaries:\n",
    "        univ_xmin, univ_ymin, univ_xmax, univ_ymax = universe_boundaries[dataset_name]\n",
    "    else:\n",
    "        # Default values if dataset not found in spatial stats\n",
    "        univ_xmin, univ_ymin, univ_xmax, univ_ymax = -180, -90, 180, 90\n",
    "    \n",
    "    Surface_univ = (univ_xmax - univ_xmin) * (univ_ymax - univ_ymin)\n",
    "    print(f\"Universe boundaries for {dataset_name}: ({univ_xmin}, {univ_ymin}, {univ_xmax}, {univ_ymax})\")\n",
    "    \n",
    "    # Load dataset - only load required columns\n",
    "    data_path = os.path.join(data_dir, csv_file)\n",
    "    print(f\"Loading data from {data_path}\")\n",
    "    data = pd.read_csv(data_path, usecols=['Query MBR', 'Count MBR'])\n",
    "    \n",
    "    # Extract query MBR column (needs parsing as it's in string format)\n",
    "    def parse_mbr(mbr_str):\n",
    "        coords = mbr_str.strip('\"()').split(', ')\n",
    "        return [float(coord) for coord in coords]\n",
    "    \n",
    "    # Extract columns - use list comprehension for better performance\n",
    "    print(\"Parsing MBR coordinates...\")\n",
    "    Rectangles = np.array([parse_mbr(mbr) for mbr in data['Query MBR']])\n",
    "    Y = data[['Count MBR']].values  # Using Count MBR as target\n",
    "    \n",
    "    # Free up memory\n",
    "    del data\n",
    "    gc.collect()\n",
    "    \n",
    "    # Calculate basic statistics\n",
    "    max_count = float(np.max(Y))\n",
    "    min_count = float(np.min(Y))\n",
    "    mean_count = float(np.mean(Y))\n",
    "    median_count = float(np.median(Y))\n",
    "    total_samples = len(Y)\n",
    "\n",
    "    # Display basic statistics for the dataset\n",
    "    print(f\"\\nBasic statistics for {dataset_name} dataset:\")\n",
    "    print(f\"Max count: {max_count}\")\n",
    "    print(f\"Min count: {min_count}\")\n",
    "    print(f\"Mean count: {mean_count:.2f}\")\n",
    "    print(f\"Median count: {median_count:.2f}\")\n",
    "    print(f\"Total samples: {total_samples}\\n\")\n",
    "\n",
    "    # Calculate rectangles density - vectorized version\n",
    "    print(\"Calculating rectangle densities...\")\n",
    "    width = Rectangles[:, 2] - Rectangles[:, 0]\n",
    "    height = Rectangles[:, 3] - Rectangles[:, 1]\n",
    "    rectanglesDensity = np.abs(width * height / Surface_univ).reshape(-1, 1)\n",
    "    \n",
    "    # Prepare the dataset\n",
    "    # X = np.append(Rectangles, rectanglesDensity, axis=1)\n",
    "    X = Rectangles\n",
    "    \n",
    "    # Split the data into 80% train and 20% test\n",
    "    print(\"Splitting data into train and test sets...\")\n",
    "    X_train, X_test_all, y_train, y_test_all = train_test_split(X, Y, test_size=0.2, random_state=3)\n",
    "    \n",
    "    # Visualize the first 1000 rectangles (only if enabled)\n",
    "    if len(Rectangles) > 0 and VISUALIZE_RECTANGLES:\n",
    "        print(\"Visualizing rectangles sample...\")\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        ax = plt.subplot()\n",
    "        \n",
    "        # Only visualize a sample to save time\n",
    "        sample_size = min(1000, len(Rectangles))\n",
    "        for i in range(sample_size):\n",
    "            x1, y1, x2, y2 = Rectangles[i]\n",
    "            color_val = float(rectanglesDensity[i][0]) if hasattr(rectanglesDensity[i], '__len__') else float(rectanglesDensity[i])\n",
    "            rectangle = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, \n",
    "                                        linewidth=1, edgecolor='b', facecolor='none', alpha=min(1.0, color_val*10))\n",
    "            ax.add_patch(rectangle)\n",
    "            \n",
    "        plt.xlim(univ_xmin-20, univ_xmax+20)\n",
    "        plt.ylim(univ_ymin-10, univ_ymax+10)\n",
    "        plt.title(f\"Sample rectangles from {dataset_name}\")\n",
    "        plt.savefig(f\"../large_files/LearnedModels/intersect/RF/visualizations/{dataset_name}_rectangles.png\", dpi=150)\n",
    "        plt.close()  # Close to free memory instead of plt.show()\n",
    "    \n",
    "    # Adjust scales to the dataset size\n",
    "    max_size = len(X_train)\n",
    "    print(f\"Training set size: {max_size}\")\n",
    "\n",
    "    if use_multiple_scales:\n",
    "        # Use multiple scales as before\n",
    "        adjusted_scales = [s for s in scales if s <= max_size]\n",
    "        \n",
    "        # Add intermediate 1 million increments for large datasets\n",
    "        if max_size > 1000000:\n",
    "            million_increments = list(range(2000000, max_size, 1000000))\n",
    "            adjusted_scales.extend(million_increments)\n",
    "            \n",
    "        # Add the actual max size if it's not already in the list\n",
    "        if max_size not in adjusted_scales:\n",
    "            adjusted_scales.append(max_size)\n",
    "            \n",
    "        # Sort the scales to ensure they're in ascending order\n",
    "        adjusted_scales.sort()\n",
    "    else:\n",
    "        # Use only the maximum scale\n",
    "        adjusted_scales = [max_size]\n",
    "\n",
    "    # List to store dataset-specific results\n",
    "    dataset_results_list = []\n",
    "\n",
    "    # Store best parameters from max scale training to reuse\n",
    "    best_params = None\n",
    "    \n",
    "    # Process scales in reversed order (largest first)\n",
    "    for sample_size in reversed(adjusted_scales):\n",
    "        print(f\"\\nTraining with sample size: {sample_size}\")\n",
    "        monitor_memory()\n",
    "        \n",
    "        # Create training subset\n",
    "        X_train_sample = X_train[:sample_size, :]\n",
    "        y_train_sample = y_train[:sample_size]\n",
    "        \n",
    "        # Random Forest Regressor parameters - optimized for performance\n",
    "        params_rf = {\n",
    "            \"n_estimators\": [50, 100, 200],\n",
    "            \"max_depth\": [10, 20, 30, None],\n",
    "            \"min_samples_split\": [2, 5, 10]\n",
    "        }\n",
    "        \n",
    "        # For very large datasets, use smaller parameter grid\n",
    "        if sample_size > 100000:\n",
    "            params_rf = {\n",
    "                \"n_estimators\": [50],\n",
    "                \"max_depth\": [None],\n",
    "                \"min_samples_split\": [5]\n",
    "            }\n",
    "            \n",
    "        # Only do GridSearch for the max scale\n",
    "        if sample_size == max_size or best_params is None:\n",
    "            print(\"Performing grid search for optimal parameters...\")\n",
    "            # Use a smaller max_features value to reduce memory usage\n",
    "            rf = RandomForestRegressor(random_state=3, max_features='sqrt', n_jobs=n_jobs)\n",
    "            rf_cv = GridSearchCV(rf, params_rf, cv=3, n_jobs=1, verbose=1)  # Use n_jobs=1 here as RF already uses parallelism\n",
    "            \n",
    "            # Time the grid search\n",
    "            t1_start = process_time()\n",
    "            rf_cv.fit(X_train_sample, y_train_sample.ravel())  # Use ravel for 1D array\n",
    "            t1_stop = process_time()\n",
    "            grid_search_time = t1_stop - t1_start\n",
    "            \n",
    "            # Store best parameters for reuse\n",
    "            best_params = rf_cv.best_params_\n",
    "            print(f\"Grid search complete in {grid_search_time:.2f}s\")\n",
    "            print(f\"Best parameters: {best_params}\")\n",
    "        else:\n",
    "            # Skip grid search for smaller scales, use params from max scale\n",
    "            rf_cv = None\n",
    "            grid_search_time = 0\n",
    "            print(f\"Using best parameters from max scale: {best_params}\")\n",
    "        \n",
    "        # Train the model with best parameters\n",
    "        print(\"Training random forest model...\")\n",
    "        rf = RandomForestRegressor(random_state=3, **best_params, n_jobs=n_jobs)\n",
    "        t2_start = process_time()\n",
    "        rf.fit(X_train_sample, y_train_sample.ravel())  # Use ravel for 1D array\n",
    "        t2_stop = process_time()\n",
    "        training_time = t2_stop - t2_start\n",
    "        \n",
    "        # Make predictions\n",
    "        print(\"Making predictions...\")\n",
    "        y_pred = rf.predict(X_test_all).reshape(-1, 1)  # Reshape to match y_test_all format\n",
    "        \n",
    "        # Calculate metrics\n",
    "        r2_score = rf.score(X_test_all, y_test_all.ravel())\n",
    "        mae_value = MAE(y_test_all, y_pred)\n",
    "        mape_value = MAPE(y_test_all, y_pred)\n",
    "        \n",
    "        # Calculate q-score - vectorized version\n",
    "        print(\"Calculating performance metrics...\")\n",
    "        \n",
    "        # Vectorized q-score calculation\n",
    "        y_true_flat = y_test_all.flatten()\n",
    "        y_pred_flat = y_pred.flatten() if y_pred.ndim > 1 else y_pred\n",
    "        \n",
    "        # Find indices where both values are non-zero\n",
    "        valid_indices = (y_true_flat != 0) & (y_pred_flat != 0)\n",
    "        \n",
    "        if np.any(valid_indices):\n",
    "            ratios = np.maximum(\n",
    "                y_pred_flat[valid_indices] / y_true_flat[valid_indices],\n",
    "                y_true_flat[valid_indices] / y_pred_flat[valid_indices]\n",
    "            )\n",
    "            q_score_mean = np.mean(ratios)\n",
    "        else:\n",
    "            q_score_mean = 0\n",
    "        \n",
    "        # Time prediction performance (10 iterations)\n",
    "        print(\"Measuring prediction performance...\")\n",
    "        total_duration = 0\n",
    "        total_read = 0\n",
    "        total_write = 0\n",
    "        \n",
    "        for _ in range(10):\n",
    "            io_before = psutil.disk_io_counters()\n",
    "            t3_start = process_time()\n",
    "            rf.predict(X_test_all)\n",
    "            t3_stop = process_time()\n",
    "            io_after = psutil.disk_io_counters()\n",
    "            \n",
    "            total_duration += (t3_stop - t3_start)\n",
    "            total_read += io_after.read_count - io_before.read_count\n",
    "            total_write += io_after.write_count - io_before.write_count\n",
    "        \n",
    "        avg_pred_time_microsec = (total_duration / 10) / len(y_pred) * 1000000\n",
    "        avg_reads = total_read / 10 / len(y_pred)\n",
    "        avg_writes = total_write / 10 / len(y_pred)\n",
    "        \n",
    "        # Save the model using joblib instead of pickle for better efficiency\n",
    "        if SAVE_INTERMEDIATE_MODELS or sample_size == max_size:\n",
    "            print(\"Saving model...\")\n",
    "            filename = f'../large_files/LearnedModels/intersect/RF/{dataset_name}_rf_{sample_size}_{training_time:.2f}s_{mape_value:.2%}_{mae_value:.2f}.joblib'\n",
    "            joblib.dump(rf, filename, compress=3)\n",
    "            # Get model file size in KB\n",
    "            model_size_kb = os.path.getsize(filename) / 1024\n",
    "            print(f\"Model size: {model_size_kb:.2f} KB\")\n",
    "        else:\n",
    "            model_size_kb = 0  # Set to 0 if model wasn't saved\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\nResults for {dataset_name}, Sample Size: {sample_size}\")\n",
    "        print(f\"Grid Search Time: {grid_search_time:.2f}s, Training Time: {training_time:.2f}s\")\n",
    "        print(f\"Random Forest Parameters: {best_params}\")\n",
    "        print(f\"Performance: R² = {r2_score:.4f}, MAE = {mae_value:.2f}, MAPE = {mape_value:.2%}\")\n",
    "        print(f\"q-score: {q_score_mean:.2f}\")\n",
    "        print(f\"Prediction time: {avg_pred_time_microsec:.4f} μs/sample\")\n",
    "        print(f\"I/O: Reads={avg_reads:.6f}, Writes={avg_writes:.6f}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Plot actual vs predicted only for the maximum scale\n",
    "        if sample_size == adjusted_scales[-1]:  # Check if this is the maximum scale\n",
    "            print(\"Generating prediction scatter plot...\")\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.scatter(y_test_all, y_pred, s=0.5, alpha=0.5)\n",
    "            plt.xlabel('True Values')\n",
    "            plt.ylabel('Predictions')\n",
    "            plt.title(f\"{dataset_name} - Sample Size: {sample_size} (Maximum)\")\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add diagonal line for perfect predictions\n",
    "            max_val = max(np.max(y_test_all), np.max(y_pred))\n",
    "            plt.plot([0, max_val], [0, max_val], 'r--', alpha=0.5)\n",
    "            \n",
    "            plt.savefig(f\"../large_files/LearnedModels/intersect/RF/visualizations/{dataset_name}_{sample_size}_prediction.png\", dpi=150)\n",
    "            plt.close()  # Close to free memory\n",
    "            \n",
    "            # Create a scatter plot comparing predicted vs real values for first 100 rectangles\n",
    "            print(\"Generating side-by-side comparison plot...\")\n",
    "            \n",
    "            # Get predictions for first 100 test samples\n",
    "            sample_indices = range(min(100, len(X_test_all)))\n",
    "            X_sample = X_test_all[sample_indices]\n",
    "            y_sample_true = y_test_all[sample_indices].flatten()\n",
    "            y_sample_pred = rf.predict(X_sample)\n",
    "            \n",
    "            plt.figure(figsize=(20, 10))\n",
    "            plt.scatter(range(len(sample_indices)), y_sample_pred, c='blue', \n",
    "                        label='Predicted number of objects (Random Forest)', alpha=0.7, s=100)\n",
    "            plt.scatter(range(len(sample_indices)), y_sample_true, c='green', \n",
    "                        label='Real number of objects', alpha=0.7, s=100)\n",
    "            \n",
    "            plt.title(f'{dataset_name} - First {len(sample_indices)} Rectangles: Predicted vs Real Values', fontsize=16)\n",
    "            plt.xlabel('Rectangle Index', fontsize=14)\n",
    "            plt.ylabel('Number of objects in rectangle', fontsize=14)\n",
    "            plt.legend(fontsize=12)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save the plot\n",
    "            plt.savefig(f\"../large_files/LearnedModels/intersect/RF/visualizations/{dataset_name}_comparison_plot.png\", dpi=150)\n",
    "            plt.close()\n",
    "        \n",
    "        # Store results in list (more efficient than DataFrame concat)\n",
    "        result_row = {\n",
    "            'Dataset': dataset_name,\n",
    "            'Sample_Size': sample_size,\n",
    "            'Training_Time': training_time,\n",
    "            'Best_Params': str(best_params),\n",
    "            'R2_Score': r2_score,\n",
    "            'MAE': mae_value,\n",
    "            'MAPE': float(mape_value),\n",
    "            'Q_Score': q_score_mean,\n",
    "            'Pred_Time_Microseconds': avg_pred_time_microsec,\n",
    "            'IO_Reads': avg_reads,\n",
    "            'IO_Writes': avg_writes,\n",
    "            'Model_Size_KB': model_size_kb,\n",
    "            'Max_Count': max_count,\n",
    "            'Min_Count': min_count,\n",
    "            'Mean_Count': mean_count,\n",
    "            'Median_Count': median_count,\n",
    "            'Total_Samples': total_samples\n",
    "        }\n",
    "        \n",
    "        dataset_results_list.append(result_row)\n",
    "        all_results_list.append(result_row)\n",
    "        \n",
    "        # Clean up to free memory\n",
    "        if sample_size != max_size:  # Don't delete for max size as we might need it\n",
    "            del X_train_sample, y_train_sample, rf\n",
    "            gc.collect()\n",
    "    \n",
    "    # Save results for this dataset\n",
    "    print(f\"Saving results for {dataset_name}...\")\n",
    "    dataset_results = pd.DataFrame(dataset_results_list)\n",
    "    dataset_results.to_csv(f'../large_files/LearnedModels/intersect/RF/results/{dataset_name}_results.csv', index=False)\n",
    "    \n",
    "    # Clear memory before next dataset\n",
    "    del X_train, X_test_all, y_train, y_test_all, Rectangles, Y, rectanglesDensity\n",
    "    gc.collect()\n",
    "    \n",
    "# Save all results\n",
    "print(\"Saving combined results...\")\n",
    "all_results = pd.DataFrame(all_results_list)\n",
    "all_results.to_csv('../large_files/LearnedModels/intersect/RF/all_results.csv', index=False)\n",
    "\n",
    "print(\"All processing completed and results saved.\")\n",
    "monitor_memory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2829.086933,
   "end_time": "2025-03-12T05:43:12.819294",
   "environment_variables": {},
   "exception": null,
   "input_path": "/home/adminlias/Spatial-Selectivity-Ext/intersect_filter/randomForestRegressor.ipynb",
   "output_path": "/home/adminlias/Spatial-Selectivity-Ext/intersect_filter/output_randomForestRegressor.ipynb",
   "parameters": {},
   "start_time": "2025-03-12T04:56:03.732361",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "37dad18f116c4792acd132cef746d4db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "496f97d2e62c45a6924f212f184c1736": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8ff16578d14f472d99fc17b49a5d11f5",
       "max": 14.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_96a69112f58f410e876edb964e998d20",
       "tabbable": null,
       "tooltip": null,
       "value": 14.0
      }
     },
     "4b18ae2e71794956905499cde714ef78": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d7271c620b914094a742e9241b8d934e",
       "placeholder": "​",
       "style": "IPY_MODEL_37dad18f116c4792acd132cef746d4db",
       "tabbable": null,
       "tooltip": null,
       "value": "Processing datasets: 100%"
      }
     },
     "61f2ff23ce904d818241b74a4e955ead": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8c02271e5bdf4cc0be0976a7b35e1a2a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4b18ae2e71794956905499cde714ef78",
        "IPY_MODEL_496f97d2e62c45a6924f212f184c1736",
        "IPY_MODEL_a5ab4c2ba5914ec7b913da169f15f432"
       ],
       "layout": "IPY_MODEL_61f2ff23ce904d818241b74a4e955ead",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8ff16578d14f472d99fc17b49a5d11f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "96a69112f58f410e876edb964e998d20": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a5ab4c2ba5914ec7b913da169f15f432": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d973b7aca0664c569e42e5498b786ae2",
       "placeholder": "​",
       "style": "IPY_MODEL_b253eed555224a84bf8d7b39d919633d",
       "tabbable": null,
       "tooltip": null,
       "value": " 14/14 [47:06&lt;00:00, 146.11s/it]"
      }
     },
     "b253eed555224a84bf8d7b39d919633d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d7271c620b914094a742e9241b8d934e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d973b7aca0664c569e42e5498b786ae2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}